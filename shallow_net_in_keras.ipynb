{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shallow_net_in_keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/hackaton-advisors/jupyter/blob/master/shallow_net_in_keras.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "quc3ZVIKIibM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Shallow Neural Network in Keras"
      ]
    },
    {
      "metadata": {
        "id": "X3N4Qn2bIibN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build a shallow neural network to classify MNIST digits"
      ]
    },
    {
      "metadata": {
        "id": "_ogAhzy2IibO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Set seed for reproducibility"
      ]
    },
    {
      "metadata": {
        "id": "i-G5xcT4IibP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "959d5791-db02-4b66-97e2-ee5d11ae943b"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.executable"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/bin/python3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "IjJzPx90IibT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "73802722-0113-4db3-9234-8c50e94363af"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5wrfOG_pIibW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "metadata": {
        "id": "u26BOThYIibY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0e06ff9e-b35c-4d04-cf30-057485f1f613"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpjoqvz240/pubring.gpg' created\n",
            "gpg: /tmp/tmpjoqvz240/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HRiwSyI0Iibb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ]
    },
    {
      "metadata": {
        "id": "4N6ftVypIibd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "53ea1569-bbf6-4201-b16f-05f54beda223"
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_wCxWhCiIibf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2f41abb-75d6-4189-b2d3-93b9796c4fe9"
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "metadata": {
        "id": "4szhzhMOJeDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "24feb514-c0e5-4f2e-b4e6-6a15ae47d4a3"
      },
      "cell_type": "code",
      "source": [
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "# Work around misordering of STREAM and STDIN in Jupyter.\n",
        "# https://github.com/jupyter/notebook/issues/3159\n",
        "prompt = !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass(prompt[0] + '\\n\\nEnter verification code: ')\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-faf07ab92f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mvcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n\\nEnter verification code: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hwA10px1KFFz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2295
        },
        "outputId": "c9b5818c-60e1-474d-f7fd-6d323cd490c9"
      },
      "cell_type": "code",
      "source": [
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/villecreated.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in Drive:\n",
            "010c__havainnekuvin.odt\n",
            "12113A käännös.odt\n",
            "12113B_no.doc\n",
            "12113B_no.doc.odt\n",
            "12452.doc\n",
            "12452.doc.odt\n",
            "12847-en.doc.odt\n",
            "12847 lyhyt.doc\n",
            "15yr mortgage.ods\n",
            "1st Grade Class Lists.pdf\n",
            "2007 Rave Benefits Summary (updated version).odt\n",
            "2007 Rave Benefits Summary (updated version).odt (3391ee62)\n",
            "2007 Rave Benefits Summary (updated version).odt (c8c85caf)\n",
            "2017Resume.odt\n",
            "446\n",
            "446.pdf\n",
            "9592 rakennettavuusselvitys.odt\n",
            "amtrakaugust 2009 travelexpensereportus1.ods\n",
            "Annan suostumukseni siihen, että oma ....odt\n",
            "Annaprasana of AKD4.pdf\n",
            "backpackthesierra.odt\n",
            "backpackthesierra.pdf\n",
            "berkeley-questions.odt\n",
            "Bicycling directions to Mile High Cafe, California 243, Idyllwild-Pine Cove, CA.desktop\n",
            "BlackCanyon16\n",
            "box store -1702 McGaw Ave.desktop\n",
            "bu.ods\n",
            "California\n",
            "capresume.odt\n",
            "Celebration of Gabe's Life.docx\n",
            "C-JDBC_Solutions_Linux_2004.pdf\n",
            "cloudcroft Shared route\n",
            "Colab Notebooks\n",
            "colorado\n",
            "ConciseResume.odt\n",
            "Configuration management:.odt\n",
            "Copy of 12113A käännös.odt\n",
            "Copy of 12113B_no.doc.odt\n",
            "Copy of capresume.odt\n",
            "Copy of Kupittaan koulu-english.odt\n",
            "data.desktop\n",
            "dlakerec.odt\n",
            "DPtoSandCanyon.desktop\n",
            "DPtoSJC.desktop\n",
            "elli  maanpää.odt\n",
            "Embassy of Saudi Arabia and Residence.odt\n",
            "expenses.ods\n",
            "Google Buzz\n",
            "GoogleResume.odt\n",
            "GOPR2026.m4v\n",
            "GOPR2027.m4v\n",
            "GOPR2028 (b88ad6dc).m4v\n",
            "GOPR2028 (feab141b).m4v\n",
            "GOPR2028.m4v\n",
            "GOPR2029 (335df2d6).m4v\n",
            "GOPR2029 (c90fe5b0).m4v\n",
            "GOPR2029.m4v\n",
            "GOPR2030.m4v\n",
            "GOPR2041.m4v\n",
            "GOPR2042.m4v\n",
            "GOPR2043.m4v\n",
            "GOPR2044.m4v\n",
            "Group 13 Final.odt\n",
            "home-to-work-by-bike.desktop\n",
            "image1.PNG\n",
            "Imported from Google Notebook - My Notebook .odt\n",
            "Imported from Google Notebook - Proramming - Ruby - Linux - other....odt\n",
            "Interview Travel Expense Report.odt\n",
            "IrvineNearSpectrumToDanaPointLanternVillage.desktop\n",
            "kaannos\n",
            "Kupittaan koulu, perustusten painumaselvitys_9.12.2013.doc\n",
            "Kupittaan koulu, perustusten painumaselvitys_9.12.2013.odt\n",
            "Maanpää.odt\n",
            "nexaemployeeperformancereview.odt\n",
            "Rapleaf Engineering Test.odt\n",
            "Rare Gray Wolf Appears In Western Mass.    , Rare Gray Wolf, Thou.odt\n",
            "resume_baxter.odt\n",
            "Resume-concise-2014-11-28.odt\n",
            "Resume-concise-2015-10-2.odt\n",
            "Resume-concise.odt\n",
            "resume_latest.odt\n",
            "resume_new.odt\n",
            "resume.odt\n",
            "Resume.odt\n",
            "resume.odt (e0e3a1b5)\n",
            "resume-screens.odt\n",
            "resumeVA.odt\n",
            "Reverse KT.odt\n",
            "review.odt\n",
            "Riding fear to syria.pages\n",
            "sanClementeBuilding.ods\n",
            "san_clemente_coastal_trail.desktop\n",
            "san mateo map\n",
            "Shimano+-+Java+Web+Developer.odt\n",
            "Signal_Noise_Hackathon17_Demo.pptx\n",
            "Signal_Noise_Hackathon17_Demo.pptx.pdf\n",
            "skihouse.desktop\n",
            "stan.odt\n",
            "Stephen Crawshaw.odt\n",
            "subversion_checkout_screenshot.odt\n",
            "Subversion_log_view.odt\n",
            "subversion_users.odt\n",
            "tarjous\n",
            "taviBank.ods\n",
            "Template- LOE for recent inquiries.doc\n",
            "terve.odt\n",
            "test.desktop\n",
            "tustin train to nexa.desktop\n",
            "Untitled.desktop\n",
            "Untitled.desktop (0f3da7fa)\n",
            "Untitled.desktop (9176b846)\n",
            "Untitled.desktop (c429d044)\n",
            "Untitled document.odt\n",
            "Untitled document.odt (9187dd42)\n",
            "Untitled document.odt (b21c54ef)\n",
            "Untitled document.odt (b38f02ac)\n",
            "Untitled document.odt (b5a0975f)\n",
            "Untitled document.odt (c0891625)\n",
            "Untitled document.odt (e59762a6)\n",
            "Untitled document.odt (f3da7107)\n",
            "Untitled Presentation.pdf\n",
            "Untitled Site\n",
            "Untitled spreadsheet.ods\n",
            "Untitled spreadsheet.ods (445d6c51)\n",
            "Untitled spreadsheet.ods (461ccb9c)\n",
            "Untitled spreadsheet.ods (7dc5e43c)\n",
            "Untitled spreadsheet.ods (a6735188)\n",
            "VALTAKIRJA.odt\n",
            "Varsinais-Suomen Energia_240812.doc\n",
            "ville price worksheet.ods\n",
            "ville price worksheet.ods (ce2777f6)\n",
            "walk in dp.desktop\n",
            "Wildflower_Century.gpx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S27c1s4LNbon",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2329
        },
        "outputId": "9726d9d8-5ea4-4854-94e3-0bc36dc1bc3a"
      },
      "cell_type": "code",
      "source": [
        "print('Files in Drive:')\n",
        "!ls drive/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files in Drive:\n",
            "010c__havainnekuvin.odt\n",
            "12113A käännös.odt\n",
            "12113B_no.doc\n",
            "12113B_no.doc.odt\n",
            "12452.doc\n",
            "12452.doc.odt\n",
            "12847-en.doc.odt\n",
            "12847 lyhyt.doc\n",
            "15yr mortgage.ods\n",
            "1st Grade Class Lists.pdf\n",
            "2007 Rave Benefits Summary (updated version).odt\n",
            "2007 Rave Benefits Summary (updated version).odt (3391ee62)\n",
            "2007 Rave Benefits Summary (updated version).odt (c8c85caf)\n",
            "2017Resume.odt\n",
            "446\n",
            "446.pdf\n",
            "9592 rakennettavuusselvitys.odt\n",
            "amtrakaugust 2009 travelexpensereportus1.ods\n",
            "Annan suostumukseni siihen, että oma ....odt\n",
            "Annaprasana of AKD4.pdf\n",
            "backpackthesierra.odt\n",
            "backpackthesierra.pdf\n",
            "berkeley-questions.odt\n",
            "Bicycling directions to Mile High Cafe, California 243, Idyllwild-Pine Cove, CA.desktop\n",
            "BlackCanyon16\n",
            "box store -1702 McGaw Ave.desktop\n",
            "bu.ods\n",
            "California\n",
            "capresume.odt\n",
            "Celebration of Gabe's Life.docx\n",
            "C-JDBC_Solutions_Linux_2004.pdf\n",
            "cloudcroft Shared route\n",
            "Colab Notebooks\n",
            "colorado\n",
            "ConciseResume.odt\n",
            "Configuration management:.odt\n",
            "Copy of 12113A käännös.odt\n",
            "Copy of 12113B_no.doc.odt\n",
            "Copy of capresume.odt\n",
            "Copy of Kupittaan koulu-english.odt\n",
            "data.desktop\n",
            "dlakerec.odt\n",
            "DPtoSandCanyon.desktop\n",
            "DPtoSJC.desktop\n",
            "elli  maanpää.odt\n",
            "Embassy of Saudi Arabia and Residence.odt\n",
            "expenses.ods\n",
            "Google Buzz\n",
            "GoogleResume.odt\n",
            "GOPR2026.m4v\n",
            "GOPR2027.m4v\n",
            "GOPR2028 (b88ad6dc).m4v\n",
            "GOPR2028 (feab141b).m4v\n",
            "GOPR2028.m4v\n",
            "GOPR2029 (335df2d6).m4v\n",
            "GOPR2029 (c90fe5b0).m4v\n",
            "GOPR2029.m4v\n",
            "GOPR2030.m4v\n",
            "GOPR2041.m4v\n",
            "GOPR2042.m4v\n",
            "GOPR2043.m4v\n",
            "GOPR2044.m4v\n",
            "Group 13 Final.odt\n",
            "home-to-work-by-bike.desktop\n",
            "image1.PNG\n",
            "Imported from Google Notebook - My Notebook .odt\n",
            "Imported from Google Notebook - Proramming - Ruby - Linux - other....odt\n",
            "Interview Travel Expense Report.odt\n",
            "IrvineNearSpectrumToDanaPointLanternVillage.desktop\n",
            "kaannos\n",
            "Kupittaan koulu, perustusten painumaselvitys_9.12.2013.doc\n",
            "Kupittaan koulu, perustusten painumaselvitys_9.12.2013.odt\n",
            "Maanpää.odt\n",
            "nexaemployeeperformancereview.odt\n",
            "number8.jpg\n",
            "Rapleaf Engineering Test.odt\n",
            "Rare Gray Wolf Appears In Western Mass.    , Rare Gray Wolf, Thou.odt\n",
            "resume_baxter.odt\n",
            "Resume-concise-2014-11-28.odt\n",
            "Resume-concise-2015-10-2.odt\n",
            "Resume-concise.odt\n",
            "resume_latest.odt\n",
            "resume_new.odt\n",
            "resume.odt\n",
            "Resume.odt\n",
            "resume.odt (e0e3a1b5)\n",
            "resume-screens.odt\n",
            "resumeVA.odt\n",
            "Reverse KT.odt\n",
            "review.odt\n",
            "Riding fear to syria.pages\n",
            "sanClementeBuilding.ods\n",
            "san_clemente_coastal_trail.desktop\n",
            "san mateo map\n",
            "Shimano+-+Java+Web+Developer.odt\n",
            "Signal_Noise_Hackathon17_Demo.pptx\n",
            "Signal_Noise_Hackathon17_Demo.pptx.pdf\n",
            "skihouse.desktop\n",
            "stan.odt\n",
            "Stephen Crawshaw.odt\n",
            "subversion_checkout_screenshot.odt\n",
            "Subversion_log_view.odt\n",
            "subversion_users.odt\n",
            "tarjous\n",
            "taviBank.ods\n",
            "Template- LOE for recent inquiries.doc\n",
            "terve.odt\n",
            "test.desktop\n",
            "tustin train to nexa.desktop\n",
            "Untitled.desktop\n",
            "Untitled.desktop (0f3da7fa)\n",
            "Untitled.desktop (9176b846)\n",
            "Untitled.desktop (c429d044)\n",
            "Untitled document.odt\n",
            "Untitled document.odt (9187dd42)\n",
            "Untitled document.odt (b21c54ef)\n",
            "Untitled document.odt (b38f02ac)\n",
            "Untitled document.odt (b5a0975f)\n",
            "Untitled document.odt (c0891625)\n",
            "Untitled document.odt (e59762a6)\n",
            "Untitled document.odt (f3da7107)\n",
            "Untitled Presentation.pdf\n",
            "Untitled Site\n",
            "Untitled spreadsheet.ods\n",
            "Untitled spreadsheet.ods (445d6c51)\n",
            "Untitled spreadsheet.ods (461ccb9c)\n",
            "Untitled spreadsheet.ods (7dc5e43c)\n",
            "Untitled spreadsheet.ods (a6735188)\n",
            "VALTAKIRJA.odt\n",
            "Varsinais-Suomen Energia_240812.doc\n",
            "villecreated.txt\n",
            "ville price worksheet.ods\n",
            "ville price worksheet.ods (ce2777f6)\n",
            "walk in dp.desktop\n",
            "Wildflower_Century.gpx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W8crsSdwIibk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44b5769f-d090-47ee-b2d4-fc86187e41e6"
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "UMZcIdjGIibp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "67a44a12-d11c-4dfb-cbab-e8f0a24bddce"
      },
      "cell_type": "code",
      "source": [
        "y_train[0:99]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0,\n",
              "       9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
              "       3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5,\n",
              "       6, 1, 0, 0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9,\n",
              "       0, 4, 6, 7, 4, 6, 8, 0, 7, 8, 3], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "metadata": {
        "id": "Fls8QHo2Iibs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8762a56e-c3c1-4713-9ae4-9411cdcddee6"
      },
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "0_8KgJizIiby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52e9b297-7c54-4586-8cfd-94341023f608"
      },
      "cell_type": "code",
      "source": [
        "X_test[1].shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "goOl1u9RIib1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "d9cf67d2-bdbe-4a1f-b17f-85763301e595"
      },
      "cell_type": "code",
      "source": [
        "X_test[1]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116, 125, 171,\n",
              "        255, 255, 150,  93,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253,\n",
              "        253, 253, 253, 218,  30,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253, 213,\n",
              "        142, 176, 253, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  52, 250, 253, 210,  32,  12,\n",
              "          0,   6, 206, 253, 140,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  77, 251, 210,  25,   0,   0,\n",
              "          0, 122, 248, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  31,  18,   0,   0,   0,\n",
              "          0, 209, 253, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        117, 247, 253, 198,  10,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76,\n",
              "        247, 253, 231,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128,\n",
              "        253, 253, 144,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 176, 246,\n",
              "        253, 159,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 234, 253,\n",
              "        233,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 253,\n",
              "        141,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  78, 248, 253, 189,\n",
              "         12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  19, 200, 253, 253, 141,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 253, 173,  12,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  25,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  43,  20,\n",
              "         20,  20,  20,   5,   0,   5,  20,  20,  37, 150, 150, 150, 147,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253, 253, 253,\n",
              "        253, 253, 253, 168, 143, 166, 253, 253, 253, 253, 253, 253, 253,\n",
              "        123,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 174, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 253, 253, 253, 249, 247, 247, 169, 117, 117,\n",
              "         57,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 118, 123, 123, 123,\n",
              "        166, 253, 253, 253, 155, 123, 123,  41,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "IQEi4bcyIib3",
        "colab_type": "code",
        "colab": {},
        "outputId": "967d8875-e93d-4a6c-d10e-d5b3b334973c"
      },
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "eB3lMp28Iib9",
        "colab_type": "code",
        "colab": {},
        "outputId": "507fc7c0-087d-4ff9-ad91-5151fdda948d"
      },
      "cell_type": "code",
      "source": [
        "y_test[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "rk2ug7EaIib_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Preprocess data"
      ]
    },
    {
      "metadata": {
        "id": "kuxgaQYtIicA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6aa8a86e-a3d8-431c-8774-5b95b92022ab"
      },
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_test = X_test.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jZdUBhkZIicC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a497a32b-4f6f-43df-af86-a8427c595b98"
      },
      "cell_type": "code",
      "source": [
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3WETLjUIicE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ac6b90f-7e3d-4959-996d-f44686db3493"
      },
      "cell_type": "code",
      "source": [
        "X_test[0].shape\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "ETAj6CzzIicJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2686
        },
        "outputId": "28690658-8a53-4cf6-aec7-4904f6c9b4e9"
      },
      "cell_type": "code",
      "source": [
        "X_test[0]"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "metadata": {
        "id": "j-TjxgstIicN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "95823ca1-9f72-4350-fa1d-10b733498efd"
      },
      "cell_type": "code",
      "source": [
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, n_classes)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fctTCe0CIicQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "891049b0-5dea-459d-f0da-3ba53213ca59"
      },
      "cell_type": "code",
      "source": [
        "y_test[0]"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "metadata": {
        "id": "LHQ1vLExIicU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "metadata": {
        "id": "lKFP-sm2IicU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6f9fe7c7-7e61-4e81-ad9b-0a5758dc8385"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyH3t2u8IicW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f63395a2-1301-4914-a0fe-30081eb216ea"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cAiph8eAIicZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "ea20dd96-399f-4892-ccb4-14c720831dbc"
      },
      "cell_type": "code",
      "source": [
        "(64*784)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "x7LbteHMIicd",
        "colab_type": "code",
        "colab": {},
        "outputId": "6c132d67-b0fb-4469-f3ff-02906fb38bed"
      },
      "cell_type": "code",
      "source": [
        "(64*784)+64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "x6ziAZ4bIich",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb9ba402-237d-4852-93a9-4eecd5b2ced8"
      },
      "cell_type": "code",
      "source": [
        "(10*64)+10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "zN3rT9VXIick",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Configure model"
      ]
    },
    {
      "metadata": {
        "id": "5RHGLg8AIicl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a7e7d835-d02c-464c-b0e3-5245cbaad0d5"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01), metrics=['accuracy'])"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qqiscei3Iicn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Train!"
      ]
    },
    {
      "metadata": {
        "id": "lF7GiTQ4Iicn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7426
        },
        "outputId": "78853b56-d5df-4c09-eb59-6c7066675671"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_test, y_test))\n",
        "model.save(\"drive/numberModel\")\n",
        "#reshapedimg = X_test[5].reshape(1, 784).astype('float32')\n",
        "\n",
        "#reshapedimg /= 255\n",
        "result = model.predict(X_test[5],batch_size=1)\n",
        "result\n",
        "#resultArray = np.asarray(result[0])\n",
        "#resultArray.tolist().index(max(result[0]))\n",
        "#reshapedimg\n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 2s 25us/step - loss: 0.0832 - acc: 0.3938 - val_loss: 0.0829 - val_acc: 0.4003\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0828 - acc: 0.3984 - val_loss: 0.0825 - val_acc: 0.4040\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0824 - acc: 0.4022 - val_loss: 0.0820 - val_acc: 0.4072\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0819 - acc: 0.4060 - val_loss: 0.0816 - val_acc: 0.4103\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0815 - acc: 0.4094 - val_loss: 0.0811 - val_acc: 0.4130\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0810 - acc: 0.4133 - val_loss: 0.0807 - val_acc: 0.4166\n",
            "Epoch 7/200\n",
            " 1920/60000 [..............................]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0806 - acc: 0.4172 - val_loss: 0.0802 - val_acc: 0.4191\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0801 - acc: 0.4217 - val_loss: 0.0797 - val_acc: 0.4221\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0796 - acc: 0.4257 - val_loss: 0.0792 - val_acc: 0.4270\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0791 - acc: 0.4302 - val_loss: 0.0787 - val_acc: 0.4315\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0786 - acc: 0.4350 - val_loss: 0.0782 - val_acc: 0.4376\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0781 - acc: 0.4406 - val_loss: 0.0777 - val_acc: 0.4429\n",
            "Epoch 13/200\n",
            "35200/60000 [================>.............] - ETA: 0s - loss: 0.0779 - acc: 0.4406"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0776 - acc: 0.4449 - val_loss: 0.0772 - val_acc: 0.4471\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0771 - acc: 0.4496 - val_loss: 0.0767 - val_acc: 0.4511\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0766 - acc: 0.4535 - val_loss: 0.0762 - val_acc: 0.4565\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0761 - acc: 0.4582 - val_loss: 0.0757 - val_acc: 0.4623\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0756 - acc: 0.4635 - val_loss: 0.0752 - val_acc: 0.4662\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0751 - acc: 0.4691 - val_loss: 0.0746 - val_acc: 0.4721\n",
            "Epoch 19/200\n",
            "41344/60000 [===================>..........] - ETA: 0s - loss: 0.0747 - acc: 0.4721"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0746 - acc: 0.4736 - val_loss: 0.0741 - val_acc: 0.4763\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0741 - acc: 0.4787 - val_loss: 0.0736 - val_acc: 0.4817\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0735 - acc: 0.4850 - val_loss: 0.0731 - val_acc: 0.4868\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0730 - acc: 0.4892 - val_loss: 0.0726 - val_acc: 0.4913\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0725 - acc: 0.4941 - val_loss: 0.0720 - val_acc: 0.4964\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0720 - acc: 0.4997 - val_loss: 0.0715 - val_acc: 0.5022\n",
            "Epoch 25/200\n",
            "34176/60000 [================>.............] - ETA: 0s - loss: 0.0715 - acc: 0.5063"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0715 - acc: 0.5042 - val_loss: 0.0710 - val_acc: 0.5075\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0710 - acc: 0.5097 - val_loss: 0.0705 - val_acc: 0.5125\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0705 - acc: 0.5150 - val_loss: 0.0700 - val_acc: 0.5174\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0700 - acc: 0.5193 - val_loss: 0.0694 - val_acc: 0.5224\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0695 - acc: 0.5244 - val_loss: 0.0689 - val_acc: 0.5260\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0689 - acc: 0.5288 - val_loss: 0.0684 - val_acc: 0.5307\n",
            "Epoch 31/200\n",
            "36480/60000 [=================>............] - ETA: 0s - loss: 0.0685 - acc: 0.5347"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0685 - acc: 0.5336 - val_loss: 0.0679 - val_acc: 0.5372\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0680 - acc: 0.5380 - val_loss: 0.0674 - val_acc: 0.5422\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0675 - acc: 0.5424 - val_loss: 0.0669 - val_acc: 0.5465\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0670 - acc: 0.5470 - val_loss: 0.0665 - val_acc: 0.5512\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0665 - acc: 0.5515 - val_loss: 0.0660 - val_acc: 0.5563\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0660 - acc: 0.5554 - val_loss: 0.0655 - val_acc: 0.5601\n",
            "Epoch 37/200\n",
            "30464/60000 [==============>...............] - ETA: 0s - loss: 0.0656 - acc: 0.5577"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0655 - acc: 0.5600 - val_loss: 0.0650 - val_acc: 0.5653\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0651 - acc: 0.5647 - val_loss: 0.0645 - val_acc: 0.5688\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0646 - acc: 0.5686 - val_loss: 0.0641 - val_acc: 0.5733\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0642 - acc: 0.5733 - val_loss: 0.0636 - val_acc: 0.5772\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0637 - acc: 0.5780 - val_loss: 0.0631 - val_acc: 0.5814\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0632 - acc: 0.5823 - val_loss: 0.0627 - val_acc: 0.5866\n",
            "Epoch 43/200\n",
            "25216/60000 [===========>..................] - ETA: 0s - loss: 0.0629 - acc: 0.5872"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0628 - acc: 0.5864 - val_loss: 0.0622 - val_acc: 0.5909\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0624 - acc: 0.5904 - val_loss: 0.0618 - val_acc: 0.5958\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0619 - acc: 0.5940 - val_loss: 0.0614 - val_acc: 0.6019\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0615 - acc: 0.5979 - val_loss: 0.0609 - val_acc: 0.6051\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0611 - acc: 0.6019 - val_loss: 0.0605 - val_acc: 0.6080\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0606 - acc: 0.6051 - val_loss: 0.0601 - val_acc: 0.6115\n",
            "Epoch 49/200\n",
            "32384/60000 [===============>..............] - ETA: 0s - loss: 0.0603 - acc: 0.6080"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0602 - acc: 0.6091 - val_loss: 0.0596 - val_acc: 0.6149\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0598 - acc: 0.6121 - val_loss: 0.0592 - val_acc: 0.6181\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0594 - acc: 0.6153 - val_loss: 0.0588 - val_acc: 0.6216\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0590 - acc: 0.6188 - val_loss: 0.0584 - val_acc: 0.6242\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0586 - acc: 0.6226 - val_loss: 0.0580 - val_acc: 0.6269\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0582 - acc: 0.6255 - val_loss: 0.0576 - val_acc: 0.6289\n",
            "Epoch 55/200\n",
            "34432/60000 [================>.............] - ETA: 0s - loss: 0.0579 - acc: 0.6288"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0578 - acc: 0.6288 - val_loss: 0.0572 - val_acc: 0.6325\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0574 - acc: 0.6316 - val_loss: 0.0568 - val_acc: 0.6353\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0570 - acc: 0.6346 - val_loss: 0.0564 - val_acc: 0.6384\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0566 - acc: 0.6374 - val_loss: 0.0560 - val_acc: 0.6418\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0563 - acc: 0.6400 - val_loss: 0.0557 - val_acc: 0.6447\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0559 - acc: 0.6430 - val_loss: 0.0553 - val_acc: 0.6476\n",
            "Epoch 61/200\n",
            "38912/60000 [==================>...........] - ETA: 0s - loss: 0.0555 - acc: 0.6458"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0555 - acc: 0.6460 - val_loss: 0.0549 - val_acc: 0.6508\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0552 - acc: 0.6486 - val_loss: 0.0545 - val_acc: 0.6544\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0548 - acc: 0.6514 - val_loss: 0.0542 - val_acc: 0.6573\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0544 - acc: 0.6540 - val_loss: 0.0538 - val_acc: 0.6588\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0541 - acc: 0.6559 - val_loss: 0.0535 - val_acc: 0.6619\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0537 - acc: 0.6581 - val_loss: 0.0531 - val_acc: 0.6656\n",
            "Epoch 67/200\n",
            "28928/60000 [=============>................] - ETA: 0s - loss: 0.0536 - acc: 0.6591"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0534 - acc: 0.6608 - val_loss: 0.0527 - val_acc: 0.6677\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0530 - acc: 0.6628 - val_loss: 0.0524 - val_acc: 0.6696\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0527 - acc: 0.6653 - val_loss: 0.0521 - val_acc: 0.6729\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0524 - acc: 0.6674 - val_loss: 0.0517 - val_acc: 0.6742\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0520 - acc: 0.6694 - val_loss: 0.0514 - val_acc: 0.6762\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0517 - acc: 0.6715 - val_loss: 0.0510 - val_acc: 0.6785\n",
            "Epoch 73/200\n",
            "33664/60000 [===============>..............] - ETA: 0s - loss: 0.0515 - acc: 0.6742"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0514 - acc: 0.6738 - val_loss: 0.0507 - val_acc: 0.6810\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0510 - acc: 0.6754 - val_loss: 0.0504 - val_acc: 0.6829\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0507 - acc: 0.6782 - val_loss: 0.0501 - val_acc: 0.6851\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0504 - acc: 0.6799 - val_loss: 0.0498 - val_acc: 0.6876\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0501 - acc: 0.6818 - val_loss: 0.0494 - val_acc: 0.6901\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0498 - acc: 0.6840 - val_loss: 0.0491 - val_acc: 0.6925\n",
            "Epoch 79/200\n",
            "39552/60000 [==================>...........] - ETA: 0s - loss: 0.0495 - acc: 0.6866"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0495 - acc: 0.6860 - val_loss: 0.0488 - val_acc: 0.6950\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0492 - acc: 0.6883 - val_loss: 0.0485 - val_acc: 0.6967\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0489 - acc: 0.6905 - val_loss: 0.0482 - val_acc: 0.6989\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0486 - acc: 0.6930 - val_loss: 0.0479 - val_acc: 0.7004\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0483 - acc: 0.6947 - val_loss: 0.0476 - val_acc: 0.7041\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0480 - acc: 0.6968 - val_loss: 0.0473 - val_acc: 0.7055\n",
            "Epoch 85/200\n",
            "34944/60000 [================>.............] - ETA: 0s - loss: 0.0478 - acc: 0.6973"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0477 - acc: 0.6990 - val_loss: 0.0470 - val_acc: 0.7072\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0474 - acc: 0.7018 - val_loss: 0.0467 - val_acc: 0.7095\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0471 - acc: 0.7037 - val_loss: 0.0464 - val_acc: 0.7124\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0468 - acc: 0.7064 - val_loss: 0.0462 - val_acc: 0.7146\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0466 - acc: 0.7090 - val_loss: 0.0459 - val_acc: 0.7160\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0463 - acc: 0.7114 - val_loss: 0.0456 - val_acc: 0.7190\n",
            "Epoch 91/200\n",
            "33408/60000 [===============>..............] - ETA: 0s - loss: 0.0463 - acc: 0.7124"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0460 - acc: 0.7146 - val_loss: 0.0453 - val_acc: 0.7227\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0457 - acc: 0.7167 - val_loss: 0.0450 - val_acc: 0.7268\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0455 - acc: 0.7199 - val_loss: 0.0448 - val_acc: 0.7294\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0452 - acc: 0.7223 - val_loss: 0.0445 - val_acc: 0.7315\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0449 - acc: 0.7241 - val_loss: 0.0442 - val_acc: 0.7334\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0447 - acc: 0.7268 - val_loss: 0.0440 - val_acc: 0.7363\n",
            "Epoch 97/200\n",
            "25984/60000 [===========>..................] - ETA: 0s - loss: 0.0445 - acc: 0.7269"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0444 - acc: 0.7296 - val_loss: 0.0437 - val_acc: 0.7387\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 2s 30us/step - loss: 0.0442 - acc: 0.7319 - val_loss: 0.0435 - val_acc: 0.7421\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0439 - acc: 0.7343 - val_loss: 0.0432 - val_acc: 0.7443\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0437 - acc: 0.7366 - val_loss: 0.0429 - val_acc: 0.7469\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0434 - acc: 0.7392 - val_loss: 0.0427 - val_acc: 0.7496\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0432 - acc: 0.7414 - val_loss: 0.0424 - val_acc: 0.7521\n",
            "Epoch 103/200\n",
            "33792/60000 [===============>..............] - ETA: 0s - loss: 0.0431 - acc: 0.7420"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0429 - acc: 0.7436 - val_loss: 0.0422 - val_acc: 0.7550\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0427 - acc: 0.7457 - val_loss: 0.0420 - val_acc: 0.7566\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0424 - acc: 0.7478 - val_loss: 0.0417 - val_acc: 0.7579\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0422 - acc: 0.7504 - val_loss: 0.0415 - val_acc: 0.7597\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0420 - acc: 0.7525 - val_loss: 0.0412 - val_acc: 0.7620\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0417 - acc: 0.7548 - val_loss: 0.0410 - val_acc: 0.7639\n",
            "Epoch 109/200\n",
            "39424/60000 [==================>...........] - ETA: 0s - loss: 0.0416 - acc: 0.7541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0415 - acc: 0.7566 - val_loss: 0.0408 - val_acc: 0.7656\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0413 - acc: 0.7593 - val_loss: 0.0405 - val_acc: 0.7671\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0411 - acc: 0.7611 - val_loss: 0.0403 - val_acc: 0.7691\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0408 - acc: 0.7626 - val_loss: 0.0401 - val_acc: 0.7710\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0406 - acc: 0.7652 - val_loss: 0.0399 - val_acc: 0.7732\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0404 - acc: 0.7672 - val_loss: 0.0396 - val_acc: 0.7752\n",
            "Epoch 115/200\n",
            "47232/60000 [======================>.......] - ETA: 0s - loss: 0.0403 - acc: 0.7676"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0402 - acc: 0.7693 - val_loss: 0.0394 - val_acc: 0.7770\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0400 - acc: 0.7711 - val_loss: 0.0392 - val_acc: 0.7785\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0397 - acc: 0.7733 - val_loss: 0.0390 - val_acc: 0.7797\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0395 - acc: 0.7752 - val_loss: 0.0388 - val_acc: 0.7817\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0393 - acc: 0.7780 - val_loss: 0.0385 - val_acc: 0.7835\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0391 - acc: 0.7796 - val_loss: 0.0383 - val_acc: 0.7853\n",
            "Epoch 121/200\n",
            "41216/60000 [===================>..........] - ETA: 0s - loss: 0.0390 - acc: 0.7800"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0389 - acc: 0.7812 - val_loss: 0.0381 - val_acc: 0.7875\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0387 - acc: 0.7832 - val_loss: 0.0379 - val_acc: 0.7897\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0385 - acc: 0.7851 - val_loss: 0.0377 - val_acc: 0.7921\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0383 - acc: 0.7869 - val_loss: 0.0375 - val_acc: 0.7941\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0381 - acc: 0.7892 - val_loss: 0.0373 - val_acc: 0.7963\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0379 - acc: 0.7914 - val_loss: 0.0371 - val_acc: 0.7994\n",
            "Epoch 127/200\n",
            "47104/60000 [======================>.......] - ETA: 0s - loss: 0.0376 - acc: 0.7933"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0377 - acc: 0.7930 - val_loss: 0.0369 - val_acc: 0.8006\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0375 - acc: 0.7952 - val_loss: 0.0367 - val_acc: 0.8023\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0373 - acc: 0.7965 - val_loss: 0.0365 - val_acc: 0.8039\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0371 - acc: 0.7989 - val_loss: 0.0363 - val_acc: 0.8063\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0369 - acc: 0.8007 - val_loss: 0.0361 - val_acc: 0.8088\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0367 - acc: 0.8023 - val_loss: 0.0359 - val_acc: 0.8113\n",
            "Epoch 133/200\n",
            "45824/60000 [=====================>........] - ETA: 0s - loss: 0.0364 - acc: 0.8051"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0366 - acc: 0.8042 - val_loss: 0.0357 - val_acc: 0.8135\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0364 - acc: 0.8057 - val_loss: 0.0356 - val_acc: 0.8149\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0362 - acc: 0.8074 - val_loss: 0.0354 - val_acc: 0.8166\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0360 - acc: 0.8090 - val_loss: 0.0352 - val_acc: 0.8187\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0358 - acc: 0.8108 - val_loss: 0.0350 - val_acc: 0.8205\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0356 - acc: 0.8120 - val_loss: 0.0348 - val_acc: 0.8219\n",
            "Epoch 139/200\n",
            "37632/60000 [=================>............] - ETA: 0s - loss: 0.0356 - acc: 0.8124"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0355 - acc: 0.8138 - val_loss: 0.0347 - val_acc: 0.8243\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0353 - acc: 0.8154 - val_loss: 0.0345 - val_acc: 0.8256\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0351 - acc: 0.8165 - val_loss: 0.0343 - val_acc: 0.8270\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0350 - acc: 0.8178 - val_loss: 0.0341 - val_acc: 0.8286\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0348 - acc: 0.8191 - val_loss: 0.0340 - val_acc: 0.8301\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0346 - acc: 0.8206 - val_loss: 0.0338 - val_acc: 0.8308\n",
            "Epoch 145/200\n",
            "40960/60000 [===================>..........] - ETA: 0s - loss: 0.0344 - acc: 0.8213"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0344 - acc: 0.8221 - val_loss: 0.0336 - val_acc: 0.8327\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0343 - acc: 0.8236 - val_loss: 0.0334 - val_acc: 0.8336\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0341 - acc: 0.8245 - val_loss: 0.0333 - val_acc: 0.8352\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0340 - acc: 0.8260 - val_loss: 0.0331 - val_acc: 0.8372\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0338 - acc: 0.8275 - val_loss: 0.0330 - val_acc: 0.8381\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0336 - acc: 0.8283 - val_loss: 0.0328 - val_acc: 0.8390\n",
            "Epoch 151/200\n",
            "42112/60000 [====================>.........] - ETA: 0s - loss: 0.0336 - acc: 0.8284"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0335 - acc: 0.8298 - val_loss: 0.0326 - val_acc: 0.8402\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0333 - acc: 0.8307 - val_loss: 0.0325 - val_acc: 0.8411\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0332 - acc: 0.8316 - val_loss: 0.0323 - val_acc: 0.8421\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0330 - acc: 0.8327 - val_loss: 0.0322 - val_acc: 0.8438\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0329 - acc: 0.8336 - val_loss: 0.0320 - val_acc: 0.8449\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0327 - acc: 0.8345 - val_loss: 0.0319 - val_acc: 0.8458\n",
            "Epoch 157/200\n",
            "44544/60000 [=====================>........] - ETA: 0s - loss: 0.0326 - acc: 0.8354"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0326 - acc: 0.8355 - val_loss: 0.0317 - val_acc: 0.8467\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0324 - acc: 0.8363 - val_loss: 0.0316 - val_acc: 0.8479\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0323 - acc: 0.8372 - val_loss: 0.0314 - val_acc: 0.8485\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0321 - acc: 0.8381 - val_loss: 0.0313 - val_acc: 0.8498\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0320 - acc: 0.8391 - val_loss: 0.0311 - val_acc: 0.8507\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0318 - acc: 0.8399 - val_loss: 0.0310 - val_acc: 0.8514\n",
            "Epoch 163/200\n",
            "39936/60000 [==================>...........] - ETA: 0s - loss: 0.0317 - acc: 0.8416"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0317 - acc: 0.8410 - val_loss: 0.0308 - val_acc: 0.8526\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0316 - acc: 0.8420 - val_loss: 0.0307 - val_acc: 0.8535\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0314 - acc: 0.8426 - val_loss: 0.0305 - val_acc: 0.8541\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0313 - acc: 0.8435 - val_loss: 0.0304 - val_acc: 0.8543\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0312 - acc: 0.8439 - val_loss: 0.0303 - val_acc: 0.8553\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0310 - acc: 0.8449 - val_loss: 0.0301 - val_acc: 0.8565\n",
            "Epoch 169/200\n",
            "35456/60000 [================>.............] - ETA: 0s - loss: 0.0310 - acc: 0.8445"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0309 - acc: 0.8453 - val_loss: 0.0300 - val_acc: 0.8567\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0308 - acc: 0.8460 - val_loss: 0.0299 - val_acc: 0.8572\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0306 - acc: 0.8468 - val_loss: 0.0297 - val_acc: 0.8581\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0305 - acc: 0.8474 - val_loss: 0.0296 - val_acc: 0.8588\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0304 - acc: 0.8482 - val_loss: 0.0295 - val_acc: 0.8597\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 2s 29us/step - loss: 0.0303 - acc: 0.8485 - val_loss: 0.0294 - val_acc: 0.8605\n",
            "Epoch 175/200\n",
            "33920/60000 [===============>..............] - ETA: 0s - loss: 0.0303 - acc: 0.8489"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0301 - acc: 0.8495 - val_loss: 0.0292 - val_acc: 0.8610\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0300 - acc: 0.8500 - val_loss: 0.0291 - val_acc: 0.8616\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0299 - acc: 0.8505 - val_loss: 0.0290 - val_acc: 0.8618\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0298 - acc: 0.8508 - val_loss: 0.0289 - val_acc: 0.8625\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0296 - acc: 0.8514 - val_loss: 0.0287 - val_acc: 0.8627\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0295 - acc: 0.8519 - val_loss: 0.0286 - val_acc: 0.8636\n",
            "Epoch 181/200\n",
            "47360/60000 [======================>.......] - ETA: 0s - loss: 0.0293 - acc: 0.8531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0294 - acc: 0.8526 - val_loss: 0.0285 - val_acc: 0.8639\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0293 - acc: 0.8528 - val_loss: 0.0284 - val_acc: 0.8639\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0292 - acc: 0.8535 - val_loss: 0.0283 - val_acc: 0.8645\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0291 - acc: 0.8540 - val_loss: 0.0282 - val_acc: 0.8646\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0290 - acc: 0.8544 - val_loss: 0.0280 - val_acc: 0.8648\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0288 - acc: 0.8549 - val_loss: 0.0279 - val_acc: 0.8651\n",
            "Epoch 187/200\n",
            "48640/60000 [=======================>......] - ETA: 0s - loss: 0.0287 - acc: 0.8553"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0287 - acc: 0.8554 - val_loss: 0.0278 - val_acc: 0.8652\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0286 - acc: 0.8560 - val_loss: 0.0277 - val_acc: 0.8657\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0285 - acc: 0.8563 - val_loss: 0.0276 - val_acc: 0.8660\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0284 - acc: 0.8566 - val_loss: 0.0275 - val_acc: 0.8665\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0283 - acc: 0.8572 - val_loss: 0.0274 - val_acc: 0.8670\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 2s 28us/step - loss: 0.0282 - acc: 0.8576 - val_loss: 0.0273 - val_acc: 0.8669\n",
            "Epoch 193/200\n",
            "40704/60000 [===================>..........] - ETA: 0s - loss: 0.0282 - acc: 0.8569"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0281 - acc: 0.8580 - val_loss: 0.0272 - val_acc: 0.8674\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0280 - acc: 0.8584 - val_loss: 0.0271 - val_acc: 0.8675\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0279 - acc: 0.8586 - val_loss: 0.0270 - val_acc: 0.8681\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.0278 - acc: 0.8591 - val_loss: 0.0269 - val_acc: 0.8687\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0277 - acc: 0.8594 - val_loss: 0.0268 - val_acc: 0.8691\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0276 - acc: 0.8596 - val_loss: 0.0267 - val_acc: 0.8696\n",
            "Epoch 199/200\n",
            "45056/60000 [=====================>........] - ETA: 0s - loss: 0.0277 - acc: 0.8586"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0275 - acc: 0.8601 - val_loss: 0.0266 - val_acc: 0.8699\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 2s 27us/step - loss: 0.0274 - acc: 0.8604 - val_loss: 0.0265 - val_acc: 0.8701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-94de3e08c266>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#reshapedimg /= 255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#resultArray = np.asarray(result[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1064\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_3_input to have shape (784,) but got array with shape (1,)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2gm6RNkK9RVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c0a7effb-9dfa-4af9-b082-291422751438"
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"drive/numberModel\")"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nd-wrMoAB3TR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5956fcec-3459-4914-e9ca-6ffce1ab0ad5"
      },
      "cell_type": "code",
      "source": [
        "X_test[5].shape"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "jfxl919aBVHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8b280fd9-9812-44db-f7cc-3b23fa207e19"
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"drive/numberModel\")\n",
        "test_item = X_test[5].reshape(1, 784).astype('float32')\n",
        "result = model.predict(test_item)\n",
        "result"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00098566, 0.88181424, 0.01852677, 0.02414856, 0.00332271,\n",
              "        0.01339199, 0.00313626, 0.01338676, 0.02982836, 0.01145862]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "metadata": {
        "id": "fLgpaa_uIics",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "6516a886-14b3-4cb6-ada6-29f2cdf40acd"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-acc519fcce62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                                    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                                    steps=steps)\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1769\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                                check_array_lengths=True, batch_size=None):\n\u001b[1;32m   1453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m             raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m   1455\u001b[0m                                \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m                                'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hl81_mg_Iicx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f02b90f4-44cf-4e13-ede5-6677305eb616"
      },
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ou2zYJvnIic0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b6c2f76e-7670-4ed8-831d-2e540eff930c"
      },
      "cell_type": "code",
      "source": [
        "#test8 = cv2.imread(\"number8.jpg\")\n",
        "test8 = cv2.imread(\"drive/number8.jpg\", cv2.cv2.IMREAD_GRAYSCALE)\n",
        "print(test8)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[162 163 163 ... 164 164 167]\n",
            " [159 161 163 ... 165 164 166]\n",
            " [160 160 162 ... 165 163 165]\n",
            " ...\n",
            " [134 134 133 ... 126 126 128]\n",
            " [133 133 131 ... 127 127 129]\n",
            " [131 130 129 ... 128 128 130]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pSz8UUV9NzDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b59cccc-ac0d-4096-eddc-f3aaeb4d6a24"
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JyJmc2PmIic3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86ec1cd2-3e50-45cf-daf3-114f9066a573"
      },
      "cell_type": "code",
      "source": [
        "test8.size"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "455040"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "e6EGDfuzIic6",
        "colab_type": "code",
        "colab": {},
        "outputId": "0e4f323b-cd4b-4ec3-c992-4f30db371152"
      },
      "cell_type": "code",
      "source": [
        "test2[1][2]\n",
        "#test2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "MjBs9a2wIidB",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7778ed2-65ac-421c-9cb0-f4adc537226b"
      },
      "cell_type": "code",
      "source": [
        "test2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "XOoOo-2cIidJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "6683e006-cbe4-4f33-ea34-f5866694413e"
      },
      "cell_type": "code",
      "source": [
        "resized_image_test2.size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {
        "id": "hHVrZi-EIidF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b4d60778-3af3-4dd5-eaa7-f88466962a6d"
      },
      "cell_type": "code",
      "source": [
        "resized_image= cv2.resize(test8, (28, 28)) "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KhPYkbuQIidO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4ac29d3-84f3-4211-ccec-7324ee8c72a4"
      },
      "cell_type": "code",
      "source": [
        "resized_image.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "l4qcF5znIidR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "f79576f8-6941-4c4b-b71b-e78f4fd74093"
      },
      "cell_type": "code",
      "source": [
        "resized_image"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[166, 160, 162, 159, 160, 160, 160, 162, 164, 162, 164, 161, 164,\n",
              "        160, 158, 156, 160, 162, 164, 165, 164, 166, 162, 165, 165, 162,\n",
              "        167, 166],\n",
              "       [162, 161, 160, 160, 158, 158, 158, 160, 163, 162, 163, 160, 160,\n",
              "        162, 157, 159, 162, 165, 162, 163, 164, 165, 166, 168, 159, 164,\n",
              "        163, 163],\n",
              "       [162, 161, 159, 157, 160, 160, 162, 164, 166, 164, 165, 162, 164,\n",
              "        164, 163, 162, 162, 162, 158, 159, 152, 169, 162, 161, 160, 164,\n",
              "        163, 165],\n",
              "       [160, 158, 157, 159, 159, 156, 161, 161, 163, 161, 161, 161, 162,\n",
              "        163, 161, 165, 163, 164, 160,  89, 163, 161, 163, 161, 160, 163,\n",
              "        164, 165],\n",
              "       [156, 157, 157, 159, 157, 159, 160, 163, 161, 162, 158, 163, 162,\n",
              "        157, 162, 163, 160, 164, 136, 121, 162, 156, 165, 165, 161, 160,\n",
              "        165, 163],\n",
              "       [157, 156, 158, 159, 158, 160, 161, 161, 163, 161, 162, 164, 163,\n",
              "        158, 166, 157, 146, 145,  82, 163, 167, 159, 164, 164, 160, 163,\n",
              "        165, 165],\n",
              "       [161, 160, 160, 157, 163, 158, 161, 163, 162, 163, 160, 151, 114,\n",
              "         87, 113, 134, 148,  78, 149, 162, 160, 164, 164, 160, 158, 162,\n",
              "        161, 163],\n",
              "       [147, 145, 152, 150, 149, 143, 152, 147, 150, 128,  69, 127, 150,\n",
              "        149, 147, 154, 116, 109, 151, 147, 151, 153, 155, 151, 152, 156,\n",
              "        156, 156],\n",
              "       [141, 142, 141, 141, 138, 142, 139, 106,  54, 119, 149, 150, 145,\n",
              "        147, 145, 144,  55, 145, 144, 140, 137, 138, 137, 140, 144, 144,\n",
              "        144, 147],\n",
              "       [141, 144, 140, 140, 141, 143,  41, 125, 141, 145, 146, 145, 146,\n",
              "        142, 144,  59, 130, 142, 142, 139, 134, 139, 136, 136, 144, 146,\n",
              "        145, 144],\n",
              "       [137, 140, 138, 140, 139,  50, 135, 143, 141, 143, 145, 142, 146,\n",
              "        143, 109,  92, 135, 141, 140, 139, 143, 142, 135, 138, 141, 141,\n",
              "        143, 142],\n",
              "       [139, 138, 141, 139, 141, 136,  57, 112, 143, 137, 142, 146, 144,\n",
              "        137,  54, 146, 142, 142, 139, 140, 140, 138, 136, 138, 142, 144,\n",
              "        138, 142],\n",
              "       [140, 136, 139, 140, 138, 140, 139, 102,  56,  96, 133, 143, 149,\n",
              "         58, 128, 140, 141, 143, 143, 142, 137, 138, 141, 138, 139, 138,\n",
              "        137, 144],\n",
              "       [135, 136, 136, 136, 137, 139, 140, 142, 140, 128,  77,  75,  81,\n",
              "         63, 143, 136, 144, 144, 140, 141, 140, 138, 132, 135, 139, 136,\n",
              "        142, 142],\n",
              "       [135, 132, 132, 138, 134, 139, 138, 142, 145, 141, 146, 145,  56,\n",
              "         77,  67,  95, 141, 141, 140, 141, 139, 140, 137, 128, 139, 142,\n",
              "        142, 143],\n",
              "       [133, 134, 134, 138, 137, 138, 143, 137, 140, 147, 142, 145,  51,\n",
              "        144, 140, 119,  67,  83, 139, 136, 139, 142, 134, 136, 140, 136,\n",
              "        139, 138],\n",
              "       [137, 135, 135, 134, 135, 138, 133, 136, 139, 143, 143, 138,  82,\n",
              "        144, 143, 142, 139, 123,  65, 105, 133, 133, 136, 135, 135, 139,\n",
              "        138, 137],\n",
              "       [138, 138, 138, 135, 136, 139, 136, 139, 134, 142, 142, 109,  97,\n",
              "        139, 139, 138, 135, 134, 140, 105,  83, 132, 136, 134, 137, 133,\n",
              "        138, 138],\n",
              "       [134, 137, 136, 134, 138, 135, 138, 138, 137, 142, 141,  90, 115,\n",
              "        138, 139, 136, 135, 136, 134, 136,  82, 126, 131, 133, 136, 130,\n",
              "        131, 137],\n",
              "       [134, 131, 133, 136, 134, 135, 133, 138, 137, 139, 139,  93, 100,\n",
              "        138, 131, 134, 133, 134, 136, 137,  80, 130, 128, 132, 134, 129,\n",
              "        136, 127],\n",
              "       [133, 134, 133, 133, 136, 129, 137, 135, 137, 139, 140, 116,  58,\n",
              "        130, 133, 132, 132, 133, 133, 129,  95, 129, 130, 129, 132, 131,\n",
              "        131, 131],\n",
              "       [131, 132, 130, 135, 135, 135, 131, 134, 135, 135, 136, 136,  49,\n",
              "        124, 133, 133, 134, 132, 126,  69, 130, 131, 131, 132, 130, 130,\n",
              "        131, 119],\n",
              "       [136, 129, 131, 134, 138, 134, 129, 130, 131, 128, 129, 134, 110,\n",
              "         42, 105, 129, 118,  64, 104, 131, 132, 126, 130, 128, 127, 132,\n",
              "        123, 131],\n",
              "       [137, 135, 134, 133, 133, 131, 134, 132, 129, 130, 132, 127, 129,\n",
              "        126, 104, 102, 120, 128, 128, 132, 131, 130, 128, 129, 130, 130,\n",
              "        129, 128],\n",
              "       [132, 128, 131, 134, 134, 134, 133, 133, 132, 128, 126, 130, 126,\n",
              "        134, 131, 128, 135, 133, 131, 128, 128, 129, 131, 132, 129, 129,\n",
              "        131, 133],\n",
              "       [135, 132, 131, 131, 135, 134, 135, 131, 130, 129, 129, 133, 129,\n",
              "        129, 125, 130, 130, 129, 132, 129, 126, 125, 131, 129, 126, 126,\n",
              "        126, 132],\n",
              "       [131, 134, 133, 135, 133, 130, 129, 132, 129, 133, 129, 127, 130,\n",
              "        126, 123, 124, 128, 129, 127, 127, 129, 129, 127, 129, 129, 130,\n",
              "        132, 126],\n",
              "       [131, 130, 129, 130, 126, 129, 131, 127, 128, 127, 124, 124, 127,\n",
              "        127, 130, 127, 126, 128, 127, 121, 125, 131, 131, 126, 124, 132,\n",
              "        127, 126]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "Lj4FVI7iIidU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc5d51f9-cd44-43ba-94a9-a2a6df08c0c7"
      },
      "cell_type": "code",
      "source": [
        "resized_image[15][16]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "mHGOXs4lIidZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "421cf5ea-5ab9-4f73-fe0a-27ad9b44997d"
      },
      "cell_type": "code",
      "source": [
        "28*28"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "ZqbHFlF7Iide",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#newimage = np.resize(x, [28,28])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aPMXScSnIidg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#newimage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJWrkzDRIidh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2862eb95-158d-4ae0-81e4-8e3520dfb0b9"
      },
      "cell_type": "code",
      "source": [
        "def myfunc(z):\n",
        "    return abs(z-255)\n",
        "#a = np.zeros(shape=(28,28))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HL7adVBPIidk",
        "colab_type": "code",
        "colab": {},
        "outputId": "4c7d92be-3ca8-4ab7-fa3e-f24c4149d1c1"
      },
      "cell_type": "code",
      "source": [
        "a.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "metadata": {
        "id": "3ltFE3fnIidm",
        "colab_type": "code",
        "colab": {},
        "outputId": "84e24fe2-8a1c-4a41-b633-0b9edaff1853"
      },
      "cell_type": "code",
      "source": [
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "metadata": {
        "id": "-4fkywUaIidp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4a6d795-45e3-4a4a-a5be-e180adf42a38"
      },
      "cell_type": "code",
      "source": [
        "#resized_image = resized_image.astype(np.int16)\n",
        "#import scipy.misc\n",
        "face = scipy.misc.face()\n",
        "def myfunc(z):\n",
        "    return abs(z-255)\n",
        "myfunc = np.vectorize(myfunc, otypes=[np.float])\n",
        "newA = face.astype(np.int16)\n",
        "myfunc_vec = np.vectorize(myfunc)\n",
        "result = myfunc_vec(resized_image)\n",
        "#result = myfunc_vec(resized_image_test2)\n",
        "result.size\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "NRCGAICWIidr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "3d728e20-7b3f-4bec-a315-fa1e326b7a5d"
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 89.,  95.,  93.,  96.,  95.,  95.,  95.,  93.,  91.,  93.,  91.,\n",
              "         94.,  91.,  95.,  97.,  99.,  95.,  93.,  91.,  90.,  91.,  89.,\n",
              "         93.,  90.,  90.,  93.,  88.,  89.],\n",
              "       [ 93.,  94.,  95.,  95.,  97.,  97.,  97.,  95.,  92.,  93.,  92.,\n",
              "         95.,  95.,  93.,  98.,  96.,  93.,  90.,  93.,  92.,  91.,  90.,\n",
              "         89.,  87.,  96.,  91.,  92.,  92.],\n",
              "       [ 93.,  94.,  96.,  98.,  95.,  95.,  93.,  91.,  89.,  91.,  90.,\n",
              "         93.,  91.,  91.,  92.,  93.,  93.,  93.,  97.,  96., 103.,  86.,\n",
              "         93.,  94.,  95.,  91.,  92.,  90.],\n",
              "       [ 95.,  97.,  98.,  96.,  96.,  99.,  94.,  94.,  92.,  94.,  94.,\n",
              "         94.,  93.,  92.,  94.,  90.,  92.,  91.,  95., 166.,  92.,  94.,\n",
              "         92.,  94.,  95.,  92.,  91.,  90.],\n",
              "       [ 99.,  98.,  98.,  96.,  98.,  96.,  95.,  92.,  94.,  93.,  97.,\n",
              "         92.,  93.,  98.,  93.,  92.,  95.,  91., 119., 134.,  93.,  99.,\n",
              "         90.,  90.,  94.,  95.,  90.,  92.],\n",
              "       [ 98.,  99.,  97.,  96.,  97.,  95.,  94.,  94.,  92.,  94.,  93.,\n",
              "         91.,  92.,  97.,  89.,  98., 109., 110., 173.,  92.,  88.,  96.,\n",
              "         91.,  91.,  95.,  92.,  90.,  90.],\n",
              "       [ 94.,  95.,  95.,  98.,  92.,  97.,  94.,  92.,  93.,  92.,  95.,\n",
              "        104., 141., 168., 142., 121., 107., 177., 106.,  93.,  95.,  91.,\n",
              "         91.,  95.,  97.,  93.,  94.,  92.],\n",
              "       [108., 110., 103., 105., 106., 112., 103., 108., 105., 127., 186.,\n",
              "        128., 105., 106., 108., 101., 139., 146., 104., 108., 104., 102.,\n",
              "        100., 104., 103.,  99.,  99.,  99.],\n",
              "       [114., 113., 114., 114., 117., 113., 116., 149., 201., 136., 106.,\n",
              "        105., 110., 108., 110., 111., 200., 110., 111., 115., 118., 117.,\n",
              "        118., 115., 111., 111., 111., 108.],\n",
              "       [114., 111., 115., 115., 114., 112., 214., 130., 114., 110., 109.,\n",
              "        110., 109., 113., 111., 196., 125., 113., 113., 116., 121., 116.,\n",
              "        119., 119., 111., 109., 110., 111.],\n",
              "       [118., 115., 117., 115., 116., 205., 120., 112., 114., 112., 110.,\n",
              "        113., 109., 112., 146., 163., 120., 114., 115., 116., 112., 113.,\n",
              "        120., 117., 114., 114., 112., 113.],\n",
              "       [116., 117., 114., 116., 114., 119., 198., 143., 112., 118., 113.,\n",
              "        109., 111., 118., 201., 109., 113., 113., 116., 115., 115., 117.,\n",
              "        119., 117., 113., 111., 117., 113.],\n",
              "       [115., 119., 116., 115., 117., 115., 116., 153., 199., 159., 122.,\n",
              "        112., 106., 197., 127., 115., 114., 112., 112., 113., 118., 117.,\n",
              "        114., 117., 116., 117., 118., 111.],\n",
              "       [120., 119., 119., 119., 118., 116., 115., 113., 115., 127., 178.,\n",
              "        180., 174., 192., 112., 119., 111., 111., 115., 114., 115., 117.,\n",
              "        123., 120., 116., 119., 113., 113.],\n",
              "       [120., 123., 123., 117., 121., 116., 117., 113., 110., 114., 109.,\n",
              "        110., 199., 178., 188., 160., 114., 114., 115., 114., 116., 115.,\n",
              "        118., 127., 116., 113., 113., 112.],\n",
              "       [122., 121., 121., 117., 118., 117., 112., 118., 115., 108., 113.,\n",
              "        110., 204., 111., 115., 136., 188., 172., 116., 119., 116., 113.,\n",
              "        121., 119., 115., 119., 116., 117.],\n",
              "       [118., 120., 120., 121., 120., 117., 122., 119., 116., 112., 112.,\n",
              "        117., 173., 111., 112., 113., 116., 132., 190., 150., 122., 122.,\n",
              "        119., 120., 120., 116., 117., 118.],\n",
              "       [117., 117., 117., 120., 119., 116., 119., 116., 121., 113., 113.,\n",
              "        146., 158., 116., 116., 117., 120., 121., 115., 150., 172., 123.,\n",
              "        119., 121., 118., 122., 117., 117.],\n",
              "       [121., 118., 119., 121., 117., 120., 117., 117., 118., 113., 114.,\n",
              "        165., 140., 117., 116., 119., 120., 119., 121., 119., 173., 129.,\n",
              "        124., 122., 119., 125., 124., 118.],\n",
              "       [121., 124., 122., 119., 121., 120., 122., 117., 118., 116., 116.,\n",
              "        162., 155., 117., 124., 121., 122., 121., 119., 118., 175., 125.,\n",
              "        127., 123., 121., 126., 119., 128.],\n",
              "       [122., 121., 122., 122., 119., 126., 118., 120., 118., 116., 115.,\n",
              "        139., 197., 125., 122., 123., 123., 122., 122., 126., 160., 126.,\n",
              "        125., 126., 123., 124., 124., 124.],\n",
              "       [124., 123., 125., 120., 120., 120., 124., 121., 120., 120., 119.,\n",
              "        119., 206., 131., 122., 122., 121., 123., 129., 186., 125., 124.,\n",
              "        124., 123., 125., 125., 124., 136.],\n",
              "       [119., 126., 124., 121., 117., 121., 126., 125., 124., 127., 126.,\n",
              "        121., 145., 213., 150., 126., 137., 191., 151., 124., 123., 129.,\n",
              "        125., 127., 128., 123., 132., 124.],\n",
              "       [118., 120., 121., 122., 122., 124., 121., 123., 126., 125., 123.,\n",
              "        128., 126., 129., 151., 153., 135., 127., 127., 123., 124., 125.,\n",
              "        127., 126., 125., 125., 126., 127.],\n",
              "       [123., 127., 124., 121., 121., 121., 122., 122., 123., 127., 129.,\n",
              "        125., 129., 121., 124., 127., 120., 122., 124., 127., 127., 126.,\n",
              "        124., 123., 126., 126., 124., 122.],\n",
              "       [120., 123., 124., 124., 120., 121., 120., 124., 125., 126., 126.,\n",
              "        122., 126., 126., 130., 125., 125., 126., 123., 126., 129., 130.,\n",
              "        124., 126., 129., 129., 129., 123.],\n",
              "       [124., 121., 122., 120., 122., 125., 126., 123., 126., 122., 126.,\n",
              "        128., 125., 129., 132., 131., 127., 126., 128., 128., 126., 126.,\n",
              "        128., 126., 126., 125., 123., 129.],\n",
              "       [124., 125., 126., 125., 129., 126., 124., 128., 127., 128., 131.,\n",
              "        131., 128., 128., 125., 128., 129., 127., 128., 134., 130., 124.,\n",
              "        124., 129., 131., 123., 128., 129.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "nQd5gZvqIidx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1241
        },
        "outputId": "3769f14e-4b2a-4b1f-d7ff-9abea9fdb0be"
      },
      "cell_type": "code",
      "source": [
        "result.shape\n",
        "reshapedimg = result.reshape(1, 784).astype('float32')\n",
        "reshapedimg\n",
        "#model.predict(reshapedimg)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 89.,  95.,  93.,  96.,  95.,  95.,  95.,  93.,  91.,  93.,  91.,\n",
              "         94.,  91.,  95.,  97.,  99.,  95.,  93.,  91.,  90.,  91.,  89.,\n",
              "         93.,  90.,  90.,  93.,  88.,  89.,  93.,  94.,  95.,  95.,  97.,\n",
              "         97.,  97.,  95.,  92.,  93.,  92.,  95.,  95.,  93.,  98.,  96.,\n",
              "         93.,  90.,  93.,  92.,  91.,  90.,  89.,  87.,  96.,  91.,  92.,\n",
              "         92.,  93.,  94.,  96.,  98.,  95.,  95.,  93.,  91.,  89.,  91.,\n",
              "         90.,  93.,  91.,  91.,  92.,  93.,  93.,  93.,  97.,  96., 103.,\n",
              "         86.,  93.,  94.,  95.,  91.,  92.,  90.,  95.,  97.,  98.,  96.,\n",
              "         96.,  99.,  94.,  94.,  92.,  94.,  94.,  94.,  93.,  92.,  94.,\n",
              "         90.,  92.,  91.,  95., 166.,  92.,  94.,  92.,  94.,  95.,  92.,\n",
              "         91.,  90.,  99.,  98.,  98.,  96.,  98.,  96.,  95.,  92.,  94.,\n",
              "         93.,  97.,  92.,  93.,  98.,  93.,  92.,  95.,  91., 119., 134.,\n",
              "         93.,  99.,  90.,  90.,  94.,  95.,  90.,  92.,  98.,  99.,  97.,\n",
              "         96.,  97.,  95.,  94.,  94.,  92.,  94.,  93.,  91.,  92.,  97.,\n",
              "         89.,  98., 109., 110., 173.,  92.,  88.,  96.,  91.,  91.,  95.,\n",
              "         92.,  90.,  90.,  94.,  95.,  95.,  98.,  92.,  97.,  94.,  92.,\n",
              "         93.,  92.,  95., 104., 141., 168., 142., 121., 107., 177., 106.,\n",
              "         93.,  95.,  91.,  91.,  95.,  97.,  93.,  94.,  92., 108., 110.,\n",
              "        103., 105., 106., 112., 103., 108., 105., 127., 186., 128., 105.,\n",
              "        106., 108., 101., 139., 146., 104., 108., 104., 102., 100., 104.,\n",
              "        103.,  99.,  99.,  99., 114., 113., 114., 114., 117., 113., 116.,\n",
              "        149., 201., 136., 106., 105., 110., 108., 110., 111., 200., 110.,\n",
              "        111., 115., 118., 117., 118., 115., 111., 111., 111., 108., 114.,\n",
              "        111., 115., 115., 114., 112., 214., 130., 114., 110., 109., 110.,\n",
              "        109., 113., 111., 196., 125., 113., 113., 116., 121., 116., 119.,\n",
              "        119., 111., 109., 110., 111., 118., 115., 117., 115., 116., 205.,\n",
              "        120., 112., 114., 112., 110., 113., 109., 112., 146., 163., 120.,\n",
              "        114., 115., 116., 112., 113., 120., 117., 114., 114., 112., 113.,\n",
              "        116., 117., 114., 116., 114., 119., 198., 143., 112., 118., 113.,\n",
              "        109., 111., 118., 201., 109., 113., 113., 116., 115., 115., 117.,\n",
              "        119., 117., 113., 111., 117., 113., 115., 119., 116., 115., 117.,\n",
              "        115., 116., 153., 199., 159., 122., 112., 106., 197., 127., 115.,\n",
              "        114., 112., 112., 113., 118., 117., 114., 117., 116., 117., 118.,\n",
              "        111., 120., 119., 119., 119., 118., 116., 115., 113., 115., 127.,\n",
              "        178., 180., 174., 192., 112., 119., 111., 111., 115., 114., 115.,\n",
              "        117., 123., 120., 116., 119., 113., 113., 120., 123., 123., 117.,\n",
              "        121., 116., 117., 113., 110., 114., 109., 110., 199., 178., 188.,\n",
              "        160., 114., 114., 115., 114., 116., 115., 118., 127., 116., 113.,\n",
              "        113., 112., 122., 121., 121., 117., 118., 117., 112., 118., 115.,\n",
              "        108., 113., 110., 204., 111., 115., 136., 188., 172., 116., 119.,\n",
              "        116., 113., 121., 119., 115., 119., 116., 117., 118., 120., 120.,\n",
              "        121., 120., 117., 122., 119., 116., 112., 112., 117., 173., 111.,\n",
              "        112., 113., 116., 132., 190., 150., 122., 122., 119., 120., 120.,\n",
              "        116., 117., 118., 117., 117., 117., 120., 119., 116., 119., 116.,\n",
              "        121., 113., 113., 146., 158., 116., 116., 117., 120., 121., 115.,\n",
              "        150., 172., 123., 119., 121., 118., 122., 117., 117., 121., 118.,\n",
              "        119., 121., 117., 120., 117., 117., 118., 113., 114., 165., 140.,\n",
              "        117., 116., 119., 120., 119., 121., 119., 173., 129., 124., 122.,\n",
              "        119., 125., 124., 118., 121., 124., 122., 119., 121., 120., 122.,\n",
              "        117., 118., 116., 116., 162., 155., 117., 124., 121., 122., 121.,\n",
              "        119., 118., 175., 125., 127., 123., 121., 126., 119., 128., 122.,\n",
              "        121., 122., 122., 119., 126., 118., 120., 118., 116., 115., 139.,\n",
              "        197., 125., 122., 123., 123., 122., 122., 126., 160., 126., 125.,\n",
              "        126., 123., 124., 124., 124., 124., 123., 125., 120., 120., 120.,\n",
              "        124., 121., 120., 120., 119., 119., 206., 131., 122., 122., 121.,\n",
              "        123., 129., 186., 125., 124., 124., 123., 125., 125., 124., 136.,\n",
              "        119., 126., 124., 121., 117., 121., 126., 125., 124., 127., 126.,\n",
              "        121., 145., 213., 150., 126., 137., 191., 151., 124., 123., 129.,\n",
              "        125., 127., 128., 123., 132., 124., 118., 120., 121., 122., 122.,\n",
              "        124., 121., 123., 126., 125., 123., 128., 126., 129., 151., 153.,\n",
              "        135., 127., 127., 123., 124., 125., 127., 126., 125., 125., 126.,\n",
              "        127., 123., 127., 124., 121., 121., 121., 122., 122., 123., 127.,\n",
              "        129., 125., 129., 121., 124., 127., 120., 122., 124., 127., 127.,\n",
              "        126., 124., 123., 126., 126., 124., 122., 120., 123., 124., 124.,\n",
              "        120., 121., 120., 124., 125., 126., 126., 122., 126., 126., 130.,\n",
              "        125., 125., 126., 123., 126., 129., 130., 124., 126., 129., 129.,\n",
              "        129., 123., 124., 121., 122., 120., 122., 125., 126., 123., 126.,\n",
              "        122., 126., 128., 125., 129., 132., 131., 127., 126., 128., 128.,\n",
              "        126., 126., 128., 126., 126., 125., 123., 129., 124., 125., 126.,\n",
              "        125., 129., 126., 124., 128., 127., 128., 131., 131., 128., 128.,\n",
              "        125., 128., 129., 127., 128., 134., 130., 124., 124., 129., 131.,\n",
              "        123., 128., 129.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "wl31d4e1Iid0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "e69bd881-3beb-43b1-8ea0-1051cb610064"
      },
      "cell_type": "code",
      "source": [
        "test8 = cv2.imread(\"drive/number8.jpg\", cv2.cv2.IMREAD_GRAYSCALE)\n",
        "test8 = cv2.resize(test8, (28, 28)) \n",
        "test8.shape\n",
        "test8"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[166, 160, 162, 159, 160, 160, 160, 162, 164, 162, 164, 161, 164,\n",
              "        160, 158, 156, 160, 162, 164, 165, 164, 166, 162, 165, 165, 162,\n",
              "        167, 166],\n",
              "       [162, 161, 160, 160, 158, 158, 158, 160, 163, 162, 163, 160, 160,\n",
              "        162, 157, 159, 162, 165, 162, 163, 164, 165, 166, 168, 159, 164,\n",
              "        163, 163],\n",
              "       [162, 161, 159, 157, 160, 160, 162, 164, 166, 164, 165, 162, 164,\n",
              "        164, 163, 162, 162, 162, 158, 159, 152, 169, 162, 161, 160, 164,\n",
              "        163, 165],\n",
              "       [160, 158, 157, 159, 159, 156, 161, 161, 163, 161, 161, 161, 162,\n",
              "        163, 161, 165, 163, 164, 160,  89, 163, 161, 163, 161, 160, 163,\n",
              "        164, 165],\n",
              "       [156, 157, 157, 159, 157, 159, 160, 163, 161, 162, 158, 163, 162,\n",
              "        157, 162, 163, 160, 164, 136, 121, 162, 156, 165, 165, 161, 160,\n",
              "        165, 163],\n",
              "       [157, 156, 158, 159, 158, 160, 161, 161, 163, 161, 162, 164, 163,\n",
              "        158, 166, 157, 146, 145,  82, 163, 167, 159, 164, 164, 160, 163,\n",
              "        165, 165],\n",
              "       [161, 160, 160, 157, 163, 158, 161, 163, 162, 163, 160, 151, 114,\n",
              "         87, 113, 134, 148,  78, 149, 162, 160, 164, 164, 160, 158, 162,\n",
              "        161, 163],\n",
              "       [147, 145, 152, 150, 149, 143, 152, 147, 150, 128,  69, 127, 150,\n",
              "        149, 147, 154, 116, 109, 151, 147, 151, 153, 155, 151, 152, 156,\n",
              "        156, 156],\n",
              "       [141, 142, 141, 141, 138, 142, 139, 106,  54, 119, 149, 150, 145,\n",
              "        147, 145, 144,  55, 145, 144, 140, 137, 138, 137, 140, 144, 144,\n",
              "        144, 147],\n",
              "       [141, 144, 140, 140, 141, 143,  41, 125, 141, 145, 146, 145, 146,\n",
              "        142, 144,  59, 130, 142, 142, 139, 134, 139, 136, 136, 144, 146,\n",
              "        145, 144],\n",
              "       [137, 140, 138, 140, 139,  50, 135, 143, 141, 143, 145, 142, 146,\n",
              "        143, 109,  92, 135, 141, 140, 139, 143, 142, 135, 138, 141, 141,\n",
              "        143, 142],\n",
              "       [139, 138, 141, 139, 141, 136,  57, 112, 143, 137, 142, 146, 144,\n",
              "        137,  54, 146, 142, 142, 139, 140, 140, 138, 136, 138, 142, 144,\n",
              "        138, 142],\n",
              "       [140, 136, 139, 140, 138, 140, 139, 102,  56,  96, 133, 143, 149,\n",
              "         58, 128, 140, 141, 143, 143, 142, 137, 138, 141, 138, 139, 138,\n",
              "        137, 144],\n",
              "       [135, 136, 136, 136, 137, 139, 140, 142, 140, 128,  77,  75,  81,\n",
              "         63, 143, 136, 144, 144, 140, 141, 140, 138, 132, 135, 139, 136,\n",
              "        142, 142],\n",
              "       [135, 132, 132, 138, 134, 139, 138, 142, 145, 141, 146, 145,  56,\n",
              "         77,  67,  95, 141, 141, 140, 141, 139, 140, 137, 128, 139, 142,\n",
              "        142, 143],\n",
              "       [133, 134, 134, 138, 137, 138, 143, 137, 140, 147, 142, 145,  51,\n",
              "        144, 140, 119,  67,  83, 139, 136, 139, 142, 134, 136, 140, 136,\n",
              "        139, 138],\n",
              "       [137, 135, 135, 134, 135, 138, 133, 136, 139, 143, 143, 138,  82,\n",
              "        144, 143, 142, 139, 123,  65, 105, 133, 133, 136, 135, 135, 139,\n",
              "        138, 137],\n",
              "       [138, 138, 138, 135, 136, 139, 136, 139, 134, 142, 142, 109,  97,\n",
              "        139, 139, 138, 135, 134, 140, 105,  83, 132, 136, 134, 137, 133,\n",
              "        138, 138],\n",
              "       [134, 137, 136, 134, 138, 135, 138, 138, 137, 142, 141,  90, 115,\n",
              "        138, 139, 136, 135, 136, 134, 136,  82, 126, 131, 133, 136, 130,\n",
              "        131, 137],\n",
              "       [134, 131, 133, 136, 134, 135, 133, 138, 137, 139, 139,  93, 100,\n",
              "        138, 131, 134, 133, 134, 136, 137,  80, 130, 128, 132, 134, 129,\n",
              "        136, 127],\n",
              "       [133, 134, 133, 133, 136, 129, 137, 135, 137, 139, 140, 116,  58,\n",
              "        130, 133, 132, 132, 133, 133, 129,  95, 129, 130, 129, 132, 131,\n",
              "        131, 131],\n",
              "       [131, 132, 130, 135, 135, 135, 131, 134, 135, 135, 136, 136,  49,\n",
              "        124, 133, 133, 134, 132, 126,  69, 130, 131, 131, 132, 130, 130,\n",
              "        131, 119],\n",
              "       [136, 129, 131, 134, 138, 134, 129, 130, 131, 128, 129, 134, 110,\n",
              "         42, 105, 129, 118,  64, 104, 131, 132, 126, 130, 128, 127, 132,\n",
              "        123, 131],\n",
              "       [137, 135, 134, 133, 133, 131, 134, 132, 129, 130, 132, 127, 129,\n",
              "        126, 104, 102, 120, 128, 128, 132, 131, 130, 128, 129, 130, 130,\n",
              "        129, 128],\n",
              "       [132, 128, 131, 134, 134, 134, 133, 133, 132, 128, 126, 130, 126,\n",
              "        134, 131, 128, 135, 133, 131, 128, 128, 129, 131, 132, 129, 129,\n",
              "        131, 133],\n",
              "       [135, 132, 131, 131, 135, 134, 135, 131, 130, 129, 129, 133, 129,\n",
              "        129, 125, 130, 130, 129, 132, 129, 126, 125, 131, 129, 126, 126,\n",
              "        126, 132],\n",
              "       [131, 134, 133, 135, 133, 130, 129, 132, 129, 133, 129, 127, 130,\n",
              "        126, 123, 124, 128, 129, 127, 127, 129, 129, 127, 129, 129, 130,\n",
              "        132, 126],\n",
              "       [131, 130, 129, 130, 126, 129, 131, 127, 128, 127, 124, 124, 127,\n",
              "        127, 130, 127, 126, 128, 127, 121, 125, 131, 131, 126, 124, 132,\n",
              "        127, 126]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "EL6pHZ1QIid3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d940ddf6-8ebd-4512-bf9a-9d46a77a7881"
      },
      "cell_type": "code",
      "source": [
        "result = myfunc_vec(test8)\n",
        "reshapedimg = result.reshape(1, 784).astype('float32')\n",
        "reshapedimg /= 255"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1lQSy6YkIid4",
        "colab_type": "code",
        "colab": {},
        "outputId": "fa71f1f7-4fbe-4488-edd7-cddbb9866ca6"
      },
      "cell_type": "code",
      "source": [
        "reshapedimg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14901961, 0.14117648, 0.14901961, 0.14117648, 0.13333334,\n",
              "        0.14117648, 0.12941177, 0.14117648, 0.13725491, 0.14509805,\n",
              "        0.14901961, 0.14901961, 0.14509805, 0.14117648, 0.14901961,\n",
              "        0.13333334, 0.13333334, 0.12941177, 0.13333334, 0.13333334,\n",
              "        0.1254902 , 0.13725491, 0.15294118, 0.12941177, 0.14509805,\n",
              "        0.14901961, 0.14509805, 0.14117648, 0.14901961, 0.14509805,\n",
              "        0.13725491, 0.15686275, 0.14117648, 0.13333334, 0.12941177,\n",
              "        0.12941177, 0.14509805, 0.14509805, 0.15294118, 0.14901961,\n",
              "        0.12941177, 0.13333334, 0.14117648, 0.14117648, 0.15294118,\n",
              "        0.13333334, 0.14509805, 0.12941177, 0.13725491, 0.14901961,\n",
              "        0.13333334, 0.14509805, 0.15294118, 0.16470589, 0.14509805,\n",
              "        0.14901961, 0.14117648, 0.15294118, 0.14901961, 0.14117648,\n",
              "        0.14509805, 0.14117648, 0.13725491, 0.14117648, 0.14117648,\n",
              "        0.14509805, 0.15686275, 0.14117648, 0.13333334, 0.13725491,\n",
              "        0.14117648, 0.12156863, 0.14509805, 0.14117648, 0.14117648,\n",
              "        0.12156863, 0.13333334, 0.13725491, 0.14901961, 0.14117648,\n",
              "        0.13333334, 0.14509805, 0.13333334, 0.14117648, 0.14117648,\n",
              "        0.14117648, 0.14117648, 0.14509805, 0.14509805, 0.13725491,\n",
              "        0.13333334, 0.13333334, 0.14509805, 0.14509805, 0.14117648,\n",
              "        0.14117648, 0.14509805, 0.13333334, 0.13333334, 0.14509805,\n",
              "        0.14901961, 0.14509805, 0.15294118, 0.14117648, 0.14117648,\n",
              "        0.13333334, 0.14117648, 0.14117648, 0.13333334, 0.14117648,\n",
              "        0.14117648, 0.12941177, 0.13725491, 0.14117648, 0.13725491,\n",
              "        0.13333334, 0.14901961, 0.14117648, 0.12941177, 0.14117648,\n",
              "        0.13725491, 0.14509805, 0.14901961, 0.14901961, 0.15686275,\n",
              "        0.13725491, 0.14509805, 0.14117648, 0.14509805, 0.14901961,\n",
              "        0.14509805, 0.14901961, 0.14509805, 0.14901961, 0.11372549,\n",
              "        0.14509805, 0.12941177, 0.14117648, 0.13725491, 0.13333334,\n",
              "        0.15294118, 0.14901961, 0.14117648, 0.14901961, 0.14901961,\n",
              "        0.14901961, 0.14117648, 0.14117648, 0.14509805, 0.14509805,\n",
              "        0.14117648, 0.13725491, 0.13725491, 0.13725491, 0.13725491,\n",
              "        0.14509805, 0.13725491, 0.13725491, 0.15294118, 0.14117648,\n",
              "        0.14117648, 0.13333334, 0.13333334, 0.14117648, 0.1254902 ,\n",
              "        0.14509805, 0.14117648, 0.13725491, 0.14117648, 0.13725491,\n",
              "        0.14509805, 0.14117648, 0.14901961, 0.14509805, 0.14117648,\n",
              "        0.14509805, 0.14509805, 0.14117648, 0.15294118, 0.13725491,\n",
              "        0.13725491, 0.15686275, 0.14509805, 0.14901961, 0.14117648,\n",
              "        0.15294118, 0.14509805, 0.15294118, 0.12941177, 0.14117648,\n",
              "        0.14117648, 0.15294118, 0.14117648, 0.14117648, 0.13725491,\n",
              "        0.14509805, 0.14509805, 0.14509805, 0.14509805, 0.13333334,\n",
              "        0.15294118, 0.14509805, 0.12941177, 0.14901961, 0.14509805,\n",
              "        0.15294118, 0.14901961, 0.14901961, 0.15686275, 0.13725491,\n",
              "        0.14117648, 0.27450982, 0.19607843, 0.11764706, 0.14509805,\n",
              "        0.14509805, 0.14901961, 0.13725491, 0.15294118, 0.13725491,\n",
              "        0.14509805, 0.14117648, 0.14901961, 0.14509805, 0.14901961,\n",
              "        0.14509805, 0.15686275, 0.14117648, 0.14509805, 0.14117648,\n",
              "        0.15294118, 0.14509805, 0.15686275, 0.14117648, 0.28235295,\n",
              "        0.14509805, 0.14117648, 0.14509805, 0.14509805, 0.21568628,\n",
              "        0.23921569, 0.13725491, 0.14117648, 0.14901961, 0.14901961,\n",
              "        0.14117648, 0.14117648, 0.14901961, 0.13333334, 0.13725491,\n",
              "        0.14117648, 0.13725491, 0.13725491, 0.13725491, 0.14509805,\n",
              "        0.14117648, 0.14901961, 0.14117648, 0.15294118, 0.14901961,\n",
              "        0.14509805, 0.13725491, 0.5764706 , 0.14117648, 0.14901961,\n",
              "        0.14117648, 0.14509805, 0.24313726, 0.41568628, 0.14509805,\n",
              "        0.15294118, 0.13725491, 0.15686275, 0.13333334, 0.15294118,\n",
              "        0.15686275, 0.14117648, 0.13725491, 0.13725491, 0.14117648,\n",
              "        0.14509805, 0.14117648, 0.15686275, 0.13725491, 0.13725491,\n",
              "        0.14509805, 0.14117648, 0.15294118, 0.14509805, 0.12941177,\n",
              "        0.4509804 , 0.15686275, 0.14901961, 0.14901961, 0.12941177,\n",
              "        0.3019608 , 0.34509805, 0.14509805, 0.14901961, 0.14509805,\n",
              "        0.14901961, 0.15686275, 0.16470589, 0.14901961, 0.16862746,\n",
              "        0.13725491, 0.13333334, 0.14509805, 0.15294118, 0.14509805,\n",
              "        0.14117648, 0.14509805, 0.14117648, 0.14117648, 0.14117648,\n",
              "        0.14901961, 0.15294118, 0.1882353 , 0.40392157, 0.14509805,\n",
              "        0.13333334, 0.13725491, 0.14117648, 0.38039216, 0.3882353 ,\n",
              "        0.14117648, 0.13725491, 0.14901961, 0.14509805, 0.13333334,\n",
              "        0.14117648, 0.16078432, 0.14117648, 0.14117648, 0.14509805,\n",
              "        0.14509805, 0.16078432, 0.14117648, 0.14509805, 0.13725491,\n",
              "        0.14901961, 0.14901961, 0.13725491, 0.15686275, 0.14901961,\n",
              "        0.33333334, 0.2       , 0.15294118, 0.14509805, 0.16470589,\n",
              "        0.15294118, 0.40392157, 0.30588236, 0.14509805, 0.14117648,\n",
              "        0.1254902 , 0.14117648, 0.14509805, 0.14117648, 0.14117648,\n",
              "        0.1254902 , 0.14509805, 0.14117648, 0.14509805, 0.14509805,\n",
              "        0.15294118, 0.14901961, 0.15294118, 0.14117648, 0.12941177,\n",
              "        0.13333334, 0.13725491, 0.13725491, 0.40392157, 0.14509805,\n",
              "        0.11764706, 0.14901961, 0.14117648, 0.14901961, 0.47058824,\n",
              "        0.5019608 , 0.14117648, 0.13725491, 0.13725491, 0.14901961,\n",
              "        0.15294118, 0.14117648, 0.14509805, 0.14509805, 0.14117648,\n",
              "        0.14117648, 0.13725491, 0.14901961, 0.14509805, 0.14509805,\n",
              "        0.13725491, 0.14117648, 0.14901961, 0.15686275, 0.15294118,\n",
              "        0.14901961, 0.13725491, 0.14509805, 0.14901961, 0.14117648,\n",
              "        0.16078432, 0.15686275, 0.40784314, 0.38431373, 0.13725491,\n",
              "        0.13333334, 0.13725491, 0.14117648, 0.14509805, 0.14117648,\n",
              "        0.14117648, 0.13725491, 0.14117648, 0.13333334, 0.14509805,\n",
              "        0.13725491, 0.15686275, 0.14509805, 0.14509805, 0.14901961,\n",
              "        0.13725491, 0.16078432, 0.14901961, 0.14117648, 0.14117648,\n",
              "        0.14901961, 0.14509805, 0.15686275, 0.13725491, 0.14509805,\n",
              "        0.43529412, 0.41960785, 0.14901961, 0.14117648, 0.14901961,\n",
              "        0.13333334, 0.12941177, 0.14901961, 0.14509805, 0.15294118,\n",
              "        0.14509805, 0.14901961, 0.15294118, 0.13333334, 0.14117648,\n",
              "        0.14509805, 0.14117648, 0.16862746, 0.14901961, 0.15686275,\n",
              "        0.14509805, 0.14901961, 0.15294118, 0.13333334, 0.14901961,\n",
              "        0.14509805, 0.14901961, 0.15294118, 0.24313726, 0.39607844,\n",
              "        0.13333334, 0.14509805, 0.14117648, 0.14509805, 0.15294118,\n",
              "        0.14509805, 0.14509805, 0.16470589, 0.15686275, 0.14901961,\n",
              "        0.14117648, 0.16078432, 0.14901961, 0.15294118, 0.14509805,\n",
              "        0.14901961, 0.15686275, 0.14509805, 0.14509805, 0.14901961,\n",
              "        0.14117648, 0.14509805, 0.13333334, 0.14117648, 0.14117648,\n",
              "        0.13333334, 0.21568628, 0.35686275, 0.14117648, 0.13333334,\n",
              "        0.14117648, 0.13725491, 0.13725491, 0.14509805, 0.14509805,\n",
              "        0.14901961, 0.14901961, 0.14117648, 0.14509805, 0.14509805,\n",
              "        0.14901961, 0.14509805, 0.14901961, 0.14901961, 0.14509805,\n",
              "        0.14117648, 0.14509805, 0.14901961, 0.14117648, 0.14509805,\n",
              "        0.15294118, 0.14117648, 0.14509805, 0.13333334, 0.16078432,\n",
              "        0.45490196, 0.14901961, 0.14117648, 0.13725491, 0.14509805,\n",
              "        0.14901961, 0.14901961, 0.14509805, 0.14117648, 0.14117648,\n",
              "        0.15686275, 0.14509805, 0.15294118, 0.14509805, 0.14509805,\n",
              "        0.14117648, 0.14509805, 0.14117648, 0.15686275, 0.14509805,\n",
              "        0.13725491, 0.15686275, 0.15294118, 0.14901961, 0.15294118,\n",
              "        0.14901961, 0.13333334, 0.12941177, 0.38039216, 0.14901961,\n",
              "        0.13333334, 0.14117648, 0.14901961, 0.14117648, 0.14509805,\n",
              "        0.14117648, 0.14901961, 0.14509805, 0.14509805, 0.15294118,\n",
              "        0.14117648, 0.14901961, 0.15686275, 0.14509805, 0.14509805,\n",
              "        0.13725491, 0.14901961, 0.14117648, 0.14509805, 0.13725491,\n",
              "        0.14901961, 0.14509805, 0.13725491, 0.14901961, 0.13333334,\n",
              "        0.12941177, 0.3254902 , 0.14117648, 0.14117648, 0.14901961,\n",
              "        0.14509805, 0.13725491, 0.14117648, 0.14509805, 0.16078432,\n",
              "        0.14509805, 0.15686275, 0.14509805, 0.14901961, 0.14901961,\n",
              "        0.14509805, 0.14509805, 0.14901961, 0.14509805, 0.16078432,\n",
              "        0.16078432, 0.16078432, 0.15294118, 0.16078432, 0.14901961,\n",
              "        0.14117648, 0.14509805, 0.14117648, 0.14901961, 0.2784314 ,\n",
              "        0.1764706 , 0.15294118, 0.14509805, 0.13725491, 0.14117648,\n",
              "        0.14117648, 0.14901961, 0.14509805, 0.14509805, 0.14509805,\n",
              "        0.14117648, 0.14901961, 0.14117648, 0.15294118, 0.14509805,\n",
              "        0.13725491, 0.14901961, 0.16078432, 0.15686275, 0.15686275,\n",
              "        0.14509805, 0.14509805, 0.15294118, 0.14509805, 0.15686275,\n",
              "        0.14509805, 0.15294118, 0.15294118, 0.15294118, 0.14509805,\n",
              "        0.14901961, 0.15294118, 0.14117648, 0.15294118, 0.14509805,\n",
              "        0.13725491, 0.13725491, 0.14509805, 0.14901961, 0.13333334,\n",
              "        0.14901961, 0.13725491, 0.14901961, 0.14901961, 0.13725491,\n",
              "        0.14509805, 0.14901961, 0.14509805, 0.14901961, 0.14509805,\n",
              "        0.14901961, 0.14901961, 0.14509805, 0.14509805, 0.14901961,\n",
              "        0.16078432, 0.15686275, 0.15686275, 0.15686275, 0.15686275,\n",
              "        0.16862746, 0.14509805, 0.16078432, 0.13333334, 0.14901961,\n",
              "        0.15686275, 0.14901961, 0.16862746, 0.14901961, 0.14509805,\n",
              "        0.16078432, 0.14509805, 0.15294118, 0.15294118, 0.14901961,\n",
              "        0.15294118, 0.14117648, 0.16078432, 0.13333334, 0.16862746,\n",
              "        0.14901961, 0.16078432, 0.14509805, 0.15294118, 0.14117648,\n",
              "        0.15294118, 0.16862746, 0.14901961, 0.14509805, 0.14509805,\n",
              "        0.14509805, 0.14509805, 0.14509805, 0.14901961, 0.14509805,\n",
              "        0.14901961, 0.14509805, 0.14117648, 0.16078432, 0.16470589,\n",
              "        0.15686275, 0.15294118, 0.14509805, 0.14901961, 0.14117648,\n",
              "        0.14901961, 0.14117648, 0.16078432, 0.14117648, 0.15294118,\n",
              "        0.14901961, 0.15686275, 0.16470589, 0.14509805, 0.14117648,\n",
              "        0.13725491, 0.14117648, 0.13725491, 0.14117648, 0.13333334,\n",
              "        0.13333334, 0.14117648, 0.14117648, 0.14509805, 0.14901961,\n",
              "        0.16862746, 0.15686275, 0.14901961, 0.15686275, 0.16078432,\n",
              "        0.15294118, 0.14509805, 0.15686275, 0.14901961, 0.14901961,\n",
              "        0.15294118, 0.14901961, 0.14509805, 0.16078432, 0.15294118,\n",
              "        0.15686275, 0.15294118, 0.14117648, 0.14901961, 0.14509805,\n",
              "        0.14509805, 0.14509805, 0.13333334, 0.14509805, 0.14901961,\n",
              "        0.15294118, 0.16078432, 0.14117648, 0.15686275, 0.14901961,\n",
              "        0.15294118, 0.14509805, 0.14509805, 0.16078432, 0.16470589,\n",
              "        0.16078432, 0.15686275, 0.15294118, 0.14901961, 0.14901961,\n",
              "        0.13725491, 0.14509805, 0.15686275, 0.14509805, 0.16470589,\n",
              "        0.14509805, 0.14901961, 0.14509805, 0.14117648, 0.14117648,\n",
              "        0.14117648, 0.14509805, 0.14117648, 0.14901961]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "metadata": {
        "id": "uonBBoV_Iid7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def invert(z):\n",
        "    return abs(z-255)\n",
        "\n",
        "def brighten(z):\n",
        "    if(z<100):\n",
        "        return 0.0\n",
        "    else:\n",
        "        return z\n",
        "#a = np.zeros(shape=(28,28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Agf8b6HIid8",
        "colab_type": "code",
        "colab": {},
        "outputId": "39abcd49-8120-460f-a383-e24a27efae8f"
      },
      "cell_type": "code",
      "source": [
        "#test4 = cv2.imread(\"test4.jpg\", cv2.cv2.IMREAD_GRAYSCALE)\n",
        "#test4 = cv2.resize(test4, (28, 28)) \n",
        "#invert = np.vectorize(invert, otypes=[np.float])\n",
        "#test4 = invert(test4)\n",
        "#brighten = np.vectorize(brighten, otypes=[np.float])\n",
        "#test4 = brighten(test4)\n",
        "reshapedimg = test4.reshape(1, 784).astype('float32')\n",
        "#\n",
        "reshapedimg /= 255\n",
        "reshapedimg\n",
        "result = model.predict(reshapedimg)\n",
        "#n_classes = 10\n",
        "#keras.utils.to_categorical(result, n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00173779, 0.00195309,\n",
              "        0.00213764, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00229143, 0.0021684 , 0.00236832, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00235294, 0.00175317, 0.00147636, 0.00199923, 0.00227605,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00226067, 0.00173779,\n",
              "        0.00152249, 0.00218378, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00159938,\n",
              "        0.00138408, 0.00181469, 0.00219915, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00218378, 0.00095348, 0.00152249, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00227605, 0.00129181, 0.00110727, 0.00135333,\n",
              "        0.0020915 , 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00193772,\n",
              "        0.00095348, 0.00124567, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00218378,\n",
              "        0.00110727, 0.00103037, 0.00170704, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00152249, 0.00101499, 0.00176855,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00204537, 0.00103037, 0.00084583,\n",
              "        0.00138408, 0.00230681, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00207612,\n",
              "        0.00098424, 0.00107651, 0.00204537, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00170704, 0.00106113, 0.00112265, 0.00170704, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00170704, 0.00112265, 0.00161476,\n",
              "        0.00235294, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00233756, 0.00147636, 0.00069204,\n",
              "        0.00110727, 0.00150711, 0.0023837 , 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00202999,\n",
              "        0.00153787, 0.00163014, 0.00189158, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00135333, 0.00110727, 0.0013687 , 0.00173779,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00229143, 0.0016609 , 0.00159938, 0.00161476,\n",
              "        0.00227605, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00143022,\n",
              "        0.00101499, 0.00119954, 0.00189158, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00192234,\n",
              "        0.00119954, 0.00167628, 0.00206075, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00227605, 0.00141484, 0.00103037, 0.00124567,\n",
              "        0.00173779, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00235294, 0.00219915,\n",
              "        0.00206075, 0.00164552, 0.00146098, 0.00121492, 0.00116878,\n",
              "        0.00098424, 0.00112265, 0.00089196, 0.00081507, 0.00106113,\n",
              "        0.00104575, 0.00119954, 0.00124567, 0.00107651, 0.0007228 ,\n",
              "        0.00081507, 0.00107651, 0.0012303 , 0.00170704, 0.0023837 ,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00235294, 0.00392157,\n",
              "        0.0023837 , 0.00233756, 0.0020915 , 0.00126105, 0.00113802,\n",
              "        0.00146098, 0.0018762 , 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00222991, 0.00089196, 0.00076894, 0.00106113, 0.00183007,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.0023837 , 0.00098424,\n",
              "        0.00089196, 0.00129181, 0.00176855, 0.00232218, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00178393, 0.00130719, 0.00130719,\n",
              "        0.00179931, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.0023837 ,\n",
              "        0.00150711, 0.00073818, 0.00104575, 0.00183007, 0.00230681,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.0023837 , 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00132257, 0.00104575,\n",
              "        0.00124567, 0.00184544, 0.00202999, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00236832, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.0023837 , 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00167628, 0.0009381 , 0.00135333, 0.00167628,\n",
              "        0.00230681, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00195309,\n",
              "        0.00103037, 0.00126105, 0.00150711, 0.0021684 , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00201461, 0.00083045, 0.0012303 ,\n",
              "        0.00156863, 0.00219915, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00204537, 0.00118416, 0.00110727, 0.00138408, 0.00189158,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00193772, 0.00110727,\n",
              "        0.00130719, 0.00138408, 0.00181469, 0.0023837 , 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00219915, 0.00112265, 0.00098424, 0.00135333,\n",
              "        0.00159938, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00224529,\n",
              "        0.00164552, 0.00141484, 0.00133795, 0.00161476, 0.00232218,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.0023837 ,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.0023837 ,\n",
              "        0.00235294, 0.00229143, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00233756,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00392157, 0.00392157, 0.00392157,\n",
              "        0.00392157, 0.00392157, 0.00236832, 0.00392157]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "metadata": {
        "id": "MmKhcP1ZYWKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7dbfc47e-ba8e-4ba0-a990-c7c96d863c4a"
      },
      "cell_type": "code",
      "source": [
        "result = model.predict(reshapedimg)\n",
        "result"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11504813, 0.10483529, 0.08095919, 0.03392908, 0.15166551,\n",
              "        0.19713983, 0.03848398, 0.0961139 , 0.08815534, 0.09366971]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "6lxn3QviIid_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5494d7b-bcc4-4977-e005-e4eb5352b26e"
      },
      "cell_type": "code",
      "source": [
        "def invert(z):\n",
        "    return abs(z-255)\n",
        "invert = np.vectorize(invert, otypes=[np.float])\n",
        "test8 = invert(test8)\n",
        "cv2.imwrite(\"/Drive/testsetnum.bmp\",test8)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "xIV5iTiHIieC",
        "colab_type": "code",
        "colab": {},
        "outputId": "63709b43-5e72-4554-c0e5-2fdb0c370d13"
      },
      "cell_type": "code",
      "source": [
        "#X_test[1]\n",
        "#test4 = test4.astype(np.uint8)\n",
        "#test4\n",
        "reshapedimg = test4.reshape(1, 784).astype('float32')\n",
        "reshapedimg /= 255\n",
        "reshapedimg\n",
        "result = model.predict(reshapedimg)\n",
        "result\n",
        "#n_classes = 10\n",
        "#keras.utils.to_categorical(result, n_classes)\n",
        "\n",
        "#test4 = invert(test4)\n",
        "#test4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12673727, 0.01990256, 0.08104635, 0.08354645, 0.20915388,\n",
              "        0.2006497 , 0.05133255, 0.08735745, 0.05018364, 0.09009027]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "metadata": {
        "id": "t8RWwMGXIieH",
        "colab_type": "code",
        "colab": {},
        "outputId": "111f3632-a291-42c7-ab20-b86201b36408"
      },
      "cell_type": "code",
      "source": [
        "resultArray = np.asarray(result[0])\n",
        "resultArray.tolist().index(max(result[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "metadata": {
        "id": "rnQ3umVlIieK",
        "colab_type": "code",
        "colab": {},
        "outputId": "dde189ab-2e78-4756-9ff5-8fbac22f479e"
      },
      "cell_type": "code",
      "source": [
        "test4 = test4.astype(np.uint8)\n",
        "test4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 142, 128, 116,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 106, 114, 101,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 102, 141, 159, 125, 107,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 108, 142, 156, 113,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 151, 165, 137, 112,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 113, 193, 156,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 107, 171, 183, 167, 119,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 129, 193, 174,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 113, 183, 188, 144,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 156, 189, 140,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 122, 188, 200, 165, 105,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 120, 191, 185, 122,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 144, 186, 182, 144,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0, 144, 182, 150, 102,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 103, 159, 210, 183, 157, 100,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0, 123, 155, 149, 132,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 167, 183, 166, 142,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0, 106, 147, 151, 150, 107,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 162, 189, 177, 132,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0, 130, 177, 146, 121,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 107, 163, 188, 174, 142,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0, 102, 112, 121, 148, 160, 176, 179, 191, 182, 197, 202,\n",
              "        186, 187, 177, 174, 185, 208, 202, 185, 175, 144, 100,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0, 102,   0, 100, 103, 119, 173, 181, 160, 133,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 110, 197, 205, 186, 136,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 100, 191, 197, 171, 140, 104,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 139, 170, 170, 138,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 100, 157, 207, 187, 136, 105,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 100,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 169, 187, 174, 135, 123,   0,   0,\n",
              "          0,   0],\n",
              "       [101,   0,   0,   0, 100,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 146, 194, 167, 146, 105,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 128, 188, 173, 157, 114,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 124, 201, 175, 153, 112,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 122, 178, 183, 165, 132,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 129, 183, 170, 165, 137, 100,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 112, 182, 191, 167, 151,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0, 109, 148, 163, 168, 150, 104,   0,\n",
              "          0,   0],\n",
              "       [  0, 100,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0, 100, 102, 106,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        103,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        101,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "metadata": {
        "id": "VMIQYhaRIieL",
        "colab_type": "code",
        "colab": {},
        "outputId": "9be7a62e-bfa7-4b87-a409-5a61fc376189"
      },
      "cell_type": "code",
      "source": [
        "test4 = cv2.imread(\"test4.jpg\", cv2.cv2.IMREAD_GRAYSCALE)\n",
        "test4 = cv2.resize(test4, (28, 28)) \n",
        "invert = np.vectorize(invert, otypes=[np.float])\n",
        "test4 = invert(test4)\n",
        "brighten = np.vectorize(brighten, otypes=[np.float])\n",
        "test4 = brighten(test4)\n",
        "reshapedimg = test4.reshape(1, 784).astype('float32')\n",
        "reshapedimg /= 255\n",
        "result = model.predict(reshapedimg)\n",
        "resultArray = np.asarray(result[0])\n",
        "resultArray.tolist().index(max(result[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "metadata": {
        "id": "5gr2oL23IieS",
        "colab_type": "code",
        "colab": {},
        "outputId": "45caa9db-80c5-4686-faba-eaaf5b9532d8"
      },
      "cell_type": "code",
      "source": [
        "def invert(z):\n",
        "    return abs(z-255)\n",
        "invert_vec = np.vectorize(invert, otypes=[np.float])\n",
        "def brighten(z):\n",
        "    if(z<130):\n",
        "        return 0.0\n",
        "    if(z>150):\n",
        "        return 255.0\n",
        "    else:\n",
        "        return z\n",
        "test8 = cv2.imread(\"test2.jpg\", cv2.cv2.IMREAD_GRAYSCALE)\n",
        "test8 = cv2.resize(test8, (28, 28)) \n",
        "invert = np.vectorize(invert, otypes=[np.float])\n",
        "test8 = invert(test8)\n",
        "brighten = np.vectorize(brighten, otypes=[np.float])\n",
        "test8 = brighten(test8)\n",
        "test8 = X_test[3]\n",
        "#test8=test8.astype(np.uint8)\n",
        "cv2.imwrite(\"/Temp/testsetnum.bmp\",test8)\n",
        "reshapedimg = test8.reshape(1, 784).astype('float32')\n",
        "reshapedimg /= 255\n",
        "result = model.predict(reshapedimg)\n",
        "resultArray = np.asarray(result[0])\n",
        "resultArray.tolist().index(max(result[0]))\n",
        "#result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "metadata": {
        "id": "YwFI6MiqIieU",
        "colab_type": "code",
        "colab": {},
        "outputId": "f5443a44-c6bc-4635-823c-c440415d5974"
      },
      "cell_type": "code",
      "source": [
        "test8"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 166.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 134.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0., 173.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 141., 168., 142.,   0.,   0., 177.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 186.,\n",
              "          0.,   0.,   0.,   0.,   0., 139., 146.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 149., 201., 136.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0., 200.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0., 214., 130.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 196.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0., 205.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 146., 163.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0., 198., 143.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 201.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 153., 199., 159.,   0.,\n",
              "          0.,   0., 197.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 178.,\n",
              "        180., 174., 192.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 199., 178., 188., 160.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 204.,   0.,   0., 136., 188., 172.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 173.,   0.,   0.,   0.,   0., 132., 190., 150.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        146., 158.,   0.,   0.,   0.,   0.,   0.,   0., 150., 172.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        165., 140.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 173.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        162., 155.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 175.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        139., 197.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 160.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 206., 131.,   0.,   0.,   0.,   0.,   0., 186.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0., 136.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 145., 213., 150.,   0., 137., 191., 151.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 132.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 151., 153., 135.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 130.,   0.,   0.,   0.,   0.,   0.,   0., 130.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 132., 131.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 131.,\n",
              "        131.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 134., 130.,   0.,\n",
              "          0.,   0., 131.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "metadata": {
        "id": "Sf2ylgvJIieW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4e6e3a43-16c8-4e60-cc4f-8e2d4b24415b"
      },
      "cell_type": "code",
      "source": [
        "#X_test[1]   cv2.imwrite(\"drive/testsetnum2.bmp\",X_test[1])\n",
        "reshapedimg = X_test[1].reshape(1, 784).astype('float32')\n",
        "\n",
        "reshapedimg /= 255\n",
        "result = model.predict(reshapedimg)\n",
        "\n",
        "#result = model.predict(X_test[1])\n",
        "result"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.09048344, 0.11299986, 0.06805648, 0.0363975 , 0.17078878,\n",
              "        0.21243227, 0.03925431, 0.11154913, 0.08747695, 0.07056123]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "wnrIYAaLIieZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test8 = cv2.imread(\"test8.jpg\", cv2.cv2.IMREAD_GRAYSCALE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vie6qY_qIiec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test8 = cv2.resize(test4, (28, 28)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T0j1zlgqIiee",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eea2d5e6-78f6-46d8-ad6a-3928c00f9428"
      },
      "cell_type": "code",
      "source": [
        "cv2.imwrite(\"drive/testsetnum2.bmp\",X_test[1])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "nfBWjFxGIiej",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "invert = np.vectorize(invert, otypes=[np.float])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b1U85GgiIiek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test8 = invert(test8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZW8ZZWhtIiep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "brighten = np.vectorize(brighten, otypes=[np.float])\n",
        "test8 = brighten(test8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w8ffeqtZIieq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reshapedimg = test8.reshape(1, 784).astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a5T9IS5OIier",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reshapedimg /= 255\n",
        "result = model.predict(reshapedimg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q8TyZI6-Iieu",
        "colab_type": "code",
        "colab": {},
        "outputId": "36995aaf-4dde-499f-b68f-f6791dfdade9"
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20979929, 0.00931124, 0.11923025, 0.10231639, 0.02885046,\n",
              "        0.221767  , 0.03390548, 0.04421921, 0.15973018, 0.07087056]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 217
        }
      ]
    },
    {
      "metadata": {
        "id": "JPcYLkyxIiex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OFXiE0cgJ_s0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADXhIK_OZfc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**STARTING FRESH GOOGLE DRIVE NUMBER 8 TEST**"
      ]
    },
    {
      "metadata": {
        "id": "yJjjRKMyZmrS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e534f525-f949-4692-8198-f522d9e18ed2"
      },
      "cell_type": "code",
      "source": [
        "test8 = cv2.imread(\"drive/number8.jpg\", cv2.cv2.IMREAD_GRAYSCALE)\n",
        "#test8 = cv2.resize(test8, (28, 28)) \n",
        "#test8.shape\n",
        "test8"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[162, 163, 163, ..., 164, 164, 167],\n",
              "       [159, 161, 163, ..., 165, 164, 166],\n",
              "       [160, 160, 162, ..., 165, 163, 165],\n",
              "       ...,\n",
              "       [134, 134, 133, ..., 126, 126, 128],\n",
              "       [133, 133, 131, ..., 127, 127, 129],\n",
              "       [131, 130, 129, ..., 128, 128, 130]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "metadata": {
        "id": "sCVaPbqck5NI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dd38779a-df03-4bcd-abcc-5455303c6a8b"
      },
      "cell_type": "code",
      "source": [
        "test8"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[255., 255., 255., ..., 255., 255., 255.],\n",
              "       [255., 255., 255., ..., 255., 255., 255.],\n",
              "       [255., 255., 255., ..., 255., 255., 255.],\n",
              "       ...,\n",
              "       [134., 134., 133., ..., 126., 126., 128.],\n",
              "       [133., 133., 131., ..., 127., 127., 129.],\n",
              "       [131., 130., 129., ..., 128., 128., 130.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "Axh9RgTpZ9_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d413a1fb-e30c-402d-a8c4-d60e404e1033"
      },
      "cell_type": "code",
      "source": [
        "cv2.imwrite(\"drive/initialRead.bmp\",test8)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "WUW1p8VDiLED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7ee40f90-3384-4c4b-9d54-45c43461f81e"
      },
      "cell_type": "code",
      "source": [
        "def invert(z):\n",
        "    return abs(z-255)\n",
        "invert = np.vectorize(invert, otypes=[np.float])\n",
        "\n",
        "def brighten(z):\n",
        "    if(z<100):\n",
        "        return 0.0\n",
        "    if(z>120):\n",
        "        return 255.0\n",
        "    else:\n",
        "        return z\n",
        "brighten = np.vectorize(brighten, otypes=[np.float])\n",
        "\n",
        "\n",
        "#test8 = cv2.imread(\"test2.jpg\", cv2.cv2.IMREAD_GRAYSCALE)\n",
        "#test8 = cv2.resize(test8, (28, 28)) \n",
        "#invert = np.vectorize(invert, otypes=[np.float])\n",
        "#test8 = invert(test8)\n",
        "#brighten = np.vectorize(brighten, otypes=[np.float])\n",
        "#test8 = brighten(test8)\n",
        "#test8 = X_test[3]\n",
        "#test8=test8.astype(np.uint8)\n",
        "#cv2.imwrite(\"/Temp/testsetnum.bmp\",test8)\n",
        "#reshapedimg = test8.reshape(1, 784).astype('float32')\n",
        "#reshapedimg /= 255\n",
        "#result = model.predict(reshapedimg)\n",
        "#resultArray = np.asarray(result[0])\n",
        "#resultArray.tolist().index(max(result[0]))"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6xjMqdXniw-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05e47c37-0ab3-4ef6-d476-8c4826189fd4"
      },
      "cell_type": "code",
      "source": [
        "test8 = cv2.resize(test8, (28, 28)) \n",
        "cv2.imwrite(\"drive/afterResize.bmp\",test8)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "metadata": {
        "id": "2QbHgYIai4n_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48735a27-a3be-434e-fe24-5ab56a8a0167"
      },
      "cell_type": "code",
      "source": [
        "test8 = brighten(test8)\n",
        "cv2.imwrite(\"drive/afterBrighten.bmp\",test8)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "metadata": {
        "id": "R9-5EFwvl0BP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83f0b6a8-9e8a-480c-97e4-6420a77b68ca"
      },
      "cell_type": "code",
      "source": [
        "X_test[1].shape == test8.shape"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "metadata": {
        "id": "gaNy3bpKmKve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWKH9VOpl7OK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "76541fa6-c63f-4bbc-9897-210cb6e4a7f3"
      },
      "cell_type": "code",
      "source": [
        "X_test[1]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 116, 125, 171,\n",
              "        255, 255, 150,  93,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253,\n",
              "        253, 253, 253, 218,  30,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 169, 253, 253, 253, 213,\n",
              "        142, 176, 253, 253, 122,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  52, 250, 253, 210,  32,  12,\n",
              "          0,   6, 206, 253, 140,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  77, 251, 210,  25,   0,   0,\n",
              "          0, 122, 248, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  31,  18,   0,   0,   0,\n",
              "          0, 209, 253, 253,  65,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        117, 247, 253, 198,  10,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76,\n",
              "        247, 253, 231,  63,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 128,\n",
              "        253, 253, 144,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 176, 246,\n",
              "        253, 159,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 234, 253,\n",
              "        233,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 253,\n",
              "        141,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  78, 248, 253, 189,\n",
              "         12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  19, 200, 253, 253, 141,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 134, 253, 253, 173,  12,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  25,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253,  43,  20,\n",
              "         20,  20,  20,   5,   0,   5,  20,  20,  37, 150, 150, 150, 147,\n",
              "         10,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 248, 253, 253, 253, 253,\n",
              "        253, 253, 253, 168, 143, 166, 253, 253, 253, 253, 253, 253, 253,\n",
              "        123,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 174, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 253, 253, 253, 249, 247, 247, 169, 117, 117,\n",
              "         57,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 118, 123, 123, 123,\n",
              "        166, 253, 253, 253, 155, 123, 123,  41,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "cKhagJLljqzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dceffc69-eacd-4a56-b9f9-51ca9834d604"
      },
      "cell_type": "code",
      "source": [
        "test8 = invert(test8)\n",
        "cv2.imwrite(\"drive/afterInvert.bmp\",test8)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "metadata": {
        "id": "_3x68SQlpby1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8207dcbb-dcf6-4cb4-c92b-44aec6f7834c"
      },
      "cell_type": "code",
      "source": [
        "cv2.imwrite(\"drive/xtest1.bmp\",X_test[1])\n",
        "print(y_test[1])\n",
        "cv2.imwrite(\"drive/xtest2.bmp\",X_test[2])\n",
        "print(y_test[2])\n",
        "cv2.imwrite(\"drive/xtest3.bmp\",X_test[3])\n",
        "print(y_test[3])\n",
        "cv2.imwrite(\"drive/xtest4.bmp\",X_test[4])\n",
        "print(y_test[4])\n",
        "cv2.imwrite(\"drive/xtest5.bmp\",X_test[5])\n",
        "print(y_test[5])\n",
        "cv2.imwrite(\"drive/xtest6.bmp\",X_test[6])\n",
        "print(y_test[6])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1\n",
            "0\n",
            "4\n",
            "1\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lQqO5VypFn5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "34121140-47e8-49b2-f3cc-753d74a2921f"
      },
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"drive/numberModel\")\n",
        "test_item = X_test[4].reshape(1, 784).astype('float32')\n",
        "result = model.predict(test_item)\n",
        "result"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01396552, 0.00236517, 0.04502108, 0.00540804, 0.59070915,\n",
              "        0.02656973, 0.03823817, 0.05701685, 0.02016097, 0.20054534]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "metadata": {
        "id": "zyzP0LFvF-NA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1180072-c0d7-45ef-d23a-30ec45fac282"
      },
      "cell_type": "code",
      "source": [
        "resultArray = np.asarray(result[0])\n",
        "resultArray.tolist().index(max(result[0]))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "metadata": {
        "id": "MyWE8tOsG2qR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        },
        "outputId": "7f49bc3d-b040-4959-a95e-6395594e56a1"
      },
      "cell_type": "code",
      "source": [
        "test8"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 141., 255., 142.,   0.,   0., 255.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,\n",
              "          0.,   0.,   0.,   0.,   0., 139., 146.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 149., 255., 136.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0., 255.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0., 255.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0., 255.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0., 255.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 146., 255.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0., 255., 143.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 255.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0., 153., 255., 255.,   0.,\n",
              "          0.,   0., 255.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,\n",
              "        255., 255., 255.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 255., 255., 255., 255.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 255.,   0.,   0., 136., 255., 255.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 255.,   0.,   0.,   0.,   0.,   0., 255., 150.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        146., 255.,   0.,   0.,   0.,   0.,   0.,   0., 150., 255.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        255., 140.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        255., 155.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "        139., 255.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 255.,   0.,   0.,   0.,   0.,   0.,   0., 255.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0., 136.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0., 145., 255., 150.,   0., 137., 255., 151.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0., 151., 153., 135.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.],\n",
              "       [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "metadata": {
        "id": "NHIgyy18p-W4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ca2507b3-3e2a-44c6-f5e2-018ab4f951db"
      },
      "cell_type": "code",
      "source": [
        "reshapedimg = test8.reshape(1, 784).astype('float32')\n",
        "\n",
        "reshapedimg /= 255\n",
        "result = model.predict(reshapedimg,batch_size=1)\n",
        "result\n",
        "#resultArray = np.asarray(result[0])\n",
        "#resultArray.tolist().index(max(result[0]))\n",
        "#reshapedimg\n"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01302565, 0.17004663, 0.04450403, 0.12755741, 0.05662548,\n",
              "        0.19996311, 0.09104463, 0.01206093, 0.23275936, 0.05241282]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "metadata": {
        "id": "cuzTXdPiqmM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abfb6181-359d-4015-f85f-75bd81a5dab3"
      },
      "cell_type": "code",
      "source": [
        "y_test[4]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "vVgTNQ0vGp9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "add96119-5bd6-4d65-f690-de194cbe2752"
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37262315, 0.0005062 , 0.3953729 , 0.02133707, 0.01774011,\n",
              "        0.08782062, 0.01360968, 0.02920977, 0.05212717, 0.00965332]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "metadata": {
        "id": "2NqPCQ5Y6Wgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10a0b859-7f58-4a3d-e2cd-4a284b5b691d"
      },
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(reshapedimg) \n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "y_classes"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    }
  ]
}